# Redis阻塞问题排查方向

> - [Redis阻塞问题排查方向](https://segmentfault.com/a/1190000037753530)

Redis是典型的单线程架构，所有的读写操作都是在一条主线程中完成的。当Redis用于高并发场景时，这条线程就变成了它的生命线。如果出现阻塞，哪怕是很短时间，对于我们的应用来说都是噩梦。

## 发现阻塞

当Redis阻塞时，线上应用服务应该最先感知到，这时应用方会收到大量Redis超时异常，比如Jedis客户端会抛出JedisConnectionException异常。**常见的做法是在应用方加入异常统计并通过邮件/短信/微信报警，以便及时发现通知问题**。开发人员需要处理如何统计异常以及触发报警的时机。何时触发报警一般根据应用的并发量决定，如1分钟内超过10个异常触发报警。在实现异常统计时要注意，由于Redis调用API会分散在项目的多个地方，**每个地方都监听异常并加入监控代码必然难以维护。这时可以借助于日志系统**，如Java语言可以使用logback或log4j。当异常发生时，异常信息最终会被日志系统收集到Appender（输出目的地），默认的Appender一般是具体的日志文件，可以自定义一个Appender，用于专门统计异常和触发报警逻辑。

**借助日志系统统计异常的前提是，需要项目必须使用日志API进行异常统一输出**，比如所有的异常都通过logger.error打印，这应该作为开发规范推广。其他编程语言也可以采用类似的日志系统实现异常统计报警。应用方加入异常监控之后还存在一个问题，当开发人员接到异常报警后，通常会去线上服务器查看错误日志细节。这时如果应用操作的是多个Redis节点（比如使用Redis集群），如何决定是哪一个节点超时还是所有的节点都有超时呢？这是线上很常见的需求，但绝大多数的客户端类库并没有在异常信息中打印ip和port信息，导致无法快速定位是哪个Redis节点超时。不过修改Redis客户端成本很低，比如Jedis只需要修改Connection类下的connect、sendCommand、readProtocolWithCheckingBroken方法专门捕获连接，发送命令，协议读取事件的异常。由于客户端类库都会保存ip和port信息，当异常发生时很容易打印出对应节点的ip和port，辅助我们快速定位问题节点。

除了在应用方加入统计报警逻辑之外，还可以借助Redis监控系统发现阻塞问题，当监控系统检测到Redis运行期的一些关键指标出现不正常时会触发报警。Redis相关的监控系统开源的方案有很多，一些公司内部也会自己开发监控系统。一个可靠的Redis监控系统首先需要做到对关键指标全方位监控和异常识别，辅助开发运维人员发现定位问题。如果Redis服务没有引入监控系统作辅助支撑，对于线上的服务是非常不负责任和危险的。

## 内在原因

### API或数据结构使用不合理

#### 如何发现慢查询

Redis原生提供慢查询统计功能，执行slowlog get{n}命令**可以获取最近的n条慢查询命令**，默认对于执行超过10毫秒的命令都会记录到一个定长队列中，线上实例建议设置为1毫秒便于及时发现毫秒级以上的命令。慢查询队列长度默认128，可适当调大。慢查询本身只记录了命令执行时间，不包括数据网络传输时间和命令排队时间，因此客户端发生阻塞异常后，可能不是当前命令缓慢，而是在等待其他命令执行。需要重点比对异常和慢查询发生的时间点，确认是否有慢查询造成的命令阻塞排队。

发现慢查询后，开发人员需要作出及时调整。可以按照以下两个方向去调整：

1.  修改为**低算法度**的命令，如hgetall改为hmget等，禁用keys、sort等命令。
2.  **缩减大对象数据或把大对象拆分为多个小对象**，防止一次命令操作过多的数据。大对象拆分过程需要视具体的业务决定，如用户好友集合存储在Redis中，有些热点用户会关注大量好友，这时可以按时间或其他维度拆分到多个集合中。

#### 如何发现大对象

Redis本身提供发现大对象的工具，对应命令：redis-cli -h {ip} -p {port} bigkeys。内部原理**采用分段进行scan操作，把历史扫描过的最大对象统计出来便于分析优化**，根据结果汇总信息能非常方便地获取到大对象的键，以及不同类型数据结构的使用情况。

### CPU饱和

单线程的Redis处理命令时只能使用一个CPU。而CPU饱和是指Redis把单核CPU使用率跑到接近100%。使用top命令很容易识别出对应Redis进程的CPU使用率。CPU饱和是非常危险的，将导致Redis无法处理更多的命令，严重影响吞吐量和应用方的稳定性。

对于这种情况，**首先判断当前Redis的并发量是否达到极限，建议使用统计命令redis-cli -h {ip} -p {port} --stat获取当前Redis使用情况**，该命令每秒输出一行统计信息。

对于这种情况，垂直层面的命令优化很难达到效果，这时就需要做**集群化水平扩展**来分摊OPS压力。如果**只有**几百或几千OPS的Redis实例就接近CPU饱和是**很不正常的**，有可能使用了**高算法复杂度**的命令。还有一种情况是过度的内存优化，这种情况有些隐蔽，需要我们**根据info commandstats统计信息分析出命令不合理开销时间**。

例如Redis实例为了追求低内存使用量，**过度放宽ziplist使用条件**（修改了hash-max-ziplist-entries和hash-max-ziplist-value配置）。进程内的hash对象平均存储着上万个元素，而针对ziplist的操作算法复杂度在O（n）到O（n2）之间。虽然采用ziplist编码后hash结构内存占用会变小，但是操作变得更慢且更消耗CPU。**ziplist压缩编码是Redis用来平衡空间和效率的优化手段，不可过度使用**。

### 持久化阻塞

#### fork阻塞

fork操作发生在RDB和AOF重写时，Redis主线程调**用fork操作产生共享内存的子进程**，由子进程完成持久化文件重写工作。如果**fork操作本身耗时过长，必然会导致主线程的阻塞**。

可以执行**info stats命令**获取到latest\_fork\_usec指标，表示Redis最近一次fork操作耗时，如果耗时很大，比如超过1秒，则需要做出优化调整，如**避免使用过大的内存实例和规避fork缓慢的操作系统**等。

#### AOF刷盘阻塞

当我们开启AOF持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程每秒对AOF文件做fsync操作。当**硬盘压力过大时，fsync操作需要等待，直到写入完成**。如果主线程发现距离上一次的fsync成功超过2秒，为了数据安全性它**会阻塞直到后台线程执行fsync操作完成**。这种阻塞行为主要是硬盘压力引起，可以查看Redis日志识别出这种情况，也**可以查看info persistence统计**中的aof\_delayed\_fsync指标，每次发生fdatasync阻塞主线程时会累加。

#### HugePage写操作阻塞

子进程在执行重写期间利用**Linux写时复制技术降低内存开销**，因此只有写操作时Redis才复制要修改的内存页。对于开启Transparent HugePages的操作系统，**每次写命令引起的复制内存页单位由4K变为2MB，放大了512倍，会拖慢写操作的执行时间，导致大量写操作慢查询**。例如简单的incr命令也会出现在慢查询中。

## 外在原因

### CPU竞争

#### 进程竞争

Redis是**典型的CPU密集型应用**，不建议和其他多核CPU密集型服务**部署在一起**。当其他进程过度消耗CPU时，将严重影响Redis吞吐量。可以通过top、sar等命令定位到CPU消耗的时间点和具体进程，这个问题比较容易发现，需要调整服务之间部署结构。

#### 绑定CPU

部署Redis时为了**充分利用多核CPU，通常一台机器部署多个实例**。常见的一种优化是把Redis进程**绑定到CPU上**，用于**降低CPU频繁上下文切换的开销**。这个优化技巧正常情况下没有问题，但是**存在例外情况**。

当Redis**父进程创建子进程**进行RDB/AOF重写时，如果做了CPU绑定，会与父进程共享使用一个CPU。**子进程重写时对单核CPU使用率通常在90%以上**，父进程与子进程将产生激烈CPU竞争，极大影响Redis稳定性。因此**对于开启了持久化或参与复制的主节点不建议绑定CPU**。

### 内存交换

内存交换（swap）对于Redis来说是非常致命的，**Redis保证高性能的一个重要前提是所有的数据在内存中**。如果操作系统把Redis使用的部分内存换出到硬盘，由于内存与硬盘读写速度差几个数量级，会导致发生交换后的**Redis性能急剧下降**。识别Redis内存交换的检查方法如下：

1）查询Redis进程号：

```
> redis-cli -p 6383 info server | grep process\_id
> process\_id:4476
```

2）根据**进程号查询内存交换信息**：

> cat /proc/4476/smaps | grep Swap

如果交换量都是0KB或者个别的是4KB，则是正常现象，说明Redis进程内存没有被交换。预防内存交换的方法有：

*   保证机器充足的可用内存。
*   **确保所有Redis实例设置最大可用内存（maxmemory）**，防止极端情况下Redis内存不可控的增长。
*   **降低系统使用swap优先级**，如echo10 > /proc/sys/vm/swappiness。

### 网络问题

#### 连接拒绝

当出现网络闪断或者连接数溢出时，客户端会出现无法连接Redis的情况。我们需要区分这三种情况：网络闪断、Redis连接拒绝、连接溢出。

**1) 网络闪断**

一般发生在网络割接或者带宽耗尽的情况，对于网络闪断的识别比较难，常见的做法可以通过sar-n DEV**查看本机历史流量是否正**常，或者借助外部系统监控工具（如Ganglia）进行识别。具体问题定位需要更上层的运维支持，对于重要的Redis服务需要充分考虑部署架构的优化，尽量避免客户端与Redis之间异地跨机房调用。

**2) Redis连接拒绝**

Redis通过maxclients参数控制客户端最大连接数，默认10000。**当Redis连接数大于maxclients时会拒绝新的连接进入**，info statsrejected\_connections统计指标记录所有被拒绝连接的数量。

Redis使用**多路复用IO模型可支撑大量连接**，但是**不代表可以无限连接**。客户端访问Redis时**尽量采用NIO长连接或者连接池的方式**。

当Redis用于**大量分布式节点访问且生命周期比较短的场景时**，如比较典型的在Map/Reduce中使用Redis。因为**客户端服务存在频繁启动和销毁的情况**且**默认Redis不会主动关闭长时间闲置连接或检查关闭无效的TCP连接**，因此会导致Redis**连接数快速消耗且无法释放的问题**。这种场景下建议设置**tcp-keepalive和timeout参数让Redis主动检查和关闭无效连接**。

**3) 连接溢出**

1.  进程限制（ulimit）
2.  backlog队列溢出

#### 网络延迟

网络延迟取决于客户端到Redis服务器之间的网络环境。主要包括它们之间的物理拓扑和带宽占用情况。

网络延迟问题**经常出现在跨机房的部署结构**上，对于机房之间延迟比较严重的场景需要调整拓扑结构，如把客户端和Redis部署在同机房或同城机房等。

带宽占用主要根据当时使用率是否达到瓶颈有关，如**频繁操作Redis的大对象对于千兆网卡的机器很容易达到网卡瓶颈**，因此需要重点监控机器流量，及时发现网卡打满产生的网络延迟或通信中断等情况，而机房专线和交换机带宽一般由上层运维监控支持，通常出现瓶颈的概率较小。

#### 网卡软中断

网卡软中断是指由于**单个网卡队列只能使用一个CPU**，高并发下网卡数据**交互都集中在同一个CPU**，导致无法充分利用多核CPU的情况。

Linux在内核2.6.35以后支持Receive Packet Steering（RPS），实现了在软件层面模拟硬件的多队列网卡功能。

## 参考链接
- [Redis阻塞问题排查方向](https://segmentfault.com/a/1190000037753530)
- [第7章 Redis的噩梦：阻塞](https://book.douban.com/subject/26971561/)
- [Redis 延迟问题排查](https://redis.io/topics/latency)
