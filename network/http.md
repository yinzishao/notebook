# HTTP

### HTTP 1.0, HTTP 1.1, HTTP 2.0
- 长连接
    - 1.0 需要使用 keep-alive 告诉服务器需要建立长连接
    - 1.1 默认支持长连接
- 节约带宽
    - 1.1 支持只发送 header 信息
- HOST 域
    - 1.1 开始支持 host 域, 使同一 ip:port 能支持多个虚拟站点
- 多路复用
    - 2.0 开始多路复用技术, 一个连接并发处理多个请求, 并发请求的数量比 1.1 大了好几个数量级
- 数据压缩
    - 1.1 不支持 header 数据的压缩
    - 2.0 使用 HPACK 算法对 header 的数据进行压缩
- 服务器推送
    - 2.0 可以在web请求数据的时候, 将客户端需要的资源一起推送到客户端.
- 断点续传
    - 1.1 开始通过 [Range: bytes] 来控制从文件头偏移多少字节来传输文件

### HTTP1.0、HTTP1.1 和 HTTP2.0 的区别

> - [HTTP1.0、HTTP1.1 和 HTTP2.0 的区别](https://juejin.cn/post/6844903489596833800)

#### HTTP1.0 和 HTTP1.1 的一些区别

HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 主要区别主要体现在：

- **缓存处理**，在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了**更多的缓存控制策略**。例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。

- 带宽优化及网络连接的使用，HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，**HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206**（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

- 错误通知的管理，在 HTTP1.1 中**新增了 24 个错误状态响应码**，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

- Host 头处理，在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们**共享一个 IP 地址**。HTTP1.1 的请求消息和响应消息**都应支持 Host 头域**，且请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。

- 长连接，HTTP 1.1 支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，**在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟**，在 HTTP1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。

#### HTTP2.0 和 HTTP1.X 相比的新特性

- 新的二进制格式（Binary Format），HTTP1.x 的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认 0 和 1 的组合。基于这种考虑 HTTP2.0 的协议解析决定采用二进制格式，实现方便且健壮。

- 多路复用（MultiPlexing），即连接共享，即每一个 request 都是是用作连接共享机制的。一个 request 对应一个 id，这样一个连接上可以有多个 request，每个连接的 request 可以随机的混杂在一起，接收方可以根据 **request 的 id** 将 request 再归属到各自不同的服务端请求里面。

- header 压缩，如上文中所言，对前面提到过 HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields 表，既避免了重复 header 的传输，又减小了需要传输的大小。

- 服务端推送（server push），同 SPDY 一样，HTTP2.0 也具有 server push 功能。

> 多路复用: 在HTTP/1.1中，浏览器并发多个请求，必须使用多个TCP链接，而浏览器会对单个域名有6-8的个数限制，因此出现了散列域名等优化策略； 而在HTTP/2中，同域名下多个请求和响应可在单个TCP连接上完成, 请求之间并行处理。 考虑到大部分网站中图片请求是占比比较高的

> 浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞。多图加载CDN在http1.1情况下，而且是请求应答，导致并行加载速度很慢。影响体验。可以增加CDN的域名，资源随机域名来并行请求。http2.0因为多路复用不会有相关问题

#### HTTP2.0 的多路复用和 HTTP1.X 中的长连接复用有什么区别？

- HTTP/1.* 一次请求 - 响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；

- HTTP/1.1 Pipeling 解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的**线头阻塞**；

- HTTP/2 多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

#### 服务器推送到底是什么？

服务端推送能把客户端所需要的资源伴随着 index.html 一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。

#### 为什么需要头部压缩？
假定一个页面有 100 个资源需要加载（这个数量对于今天的 Web 而言还是挺保守的）, 而每一次请求都有 1kb 的消息头（这同样也并不少见，因为 Cookie 和引用等东西的存在）, 则至少需要多消耗 100kb 来获取这些消息头。**HTTP2.0 可以维护一个字典，差量更新 HTTP 头部，大大降低因头部传输产生的流量**。具体参考：HTTP/2 头部压缩技术介绍

#### HTTP2.0 多路复用有多好？
HTTP **性能优化的关键并不在于高带宽，而是低延迟**。TCP 连接会随着时间进行自我「调谐」，**起初会限制连接的最大速度**，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 **TCP 慢启动**。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。HTTP/2 通过**让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升**。

### HTTP/2协议“多路复用”实现原理

> - [HTTP/2协议“多路复用”实现原理](https://segmentfault.com/a/1190000016975064)

HTTP/2是一个二进制协议，其基于“帧”的结构设计，改进了很多HTTP/1.1痛点问题。下面列举一些最常被津津乐道的改进之处：

- 多路复用的流
- 头部压缩
- 资源优先级和依赖设置
- 服务器推送
- 流量控制
- 重置消息

HTTP/1.1协议的请求-响应模型大家都是熟悉的，我们用“HTTP消息”来表示一个请求-响应的过程，那么HTTP/1.1中的消息是“管道串形化”的：只有等一个消息完成之后，才能进行下一条消息；而HTTP/2中多个消息交织在了一起，这无疑提高了“通信”的效率。这就是多路复用：在一个HTTP的连接上，多路“HTTP消息”同时工作。

#### 为什么HTTP/1.1不能实现“多路复用”？

简单回答就是：**HTTP/2是基于二进制“帧”的协议，HTTP/1.1是基于“文本分割”解析的协议**。

以上就是HTTP/1.1发送请求消息的文本格式：以换行符分割每一条key:value的内容，解析这种数据用不着什么高科技，相反的，解析这种数据往往速度慢且容易出错。“服务端”需要不断的读入字节，直到遇到分隔符（这里指换行符，代码中可能使用/n或者/r/n表示），这种解析方式是可行的，并且HTTP/1.1已经被广泛使用了二十多年，这事已经做过无数次了，问题一直都是存在的：

一次只能处理一个请求或响应，因为这种以分隔符分割消息的数据，在完成之前不能停止解析。

解析这种数据无法预知需要多少内存，这会带给“服务端”很大的压力，因为它不知道要把一行要解析的内容读到多大的“缓冲区”中，在保证解析效率和速度的前提下：内存该如何分配？

#### HTTP/2帧结构设计和多路复用实现

帧的字节中保存了不同的信息，前9个字节对于每个帧都是一致的，“服务器”解析HTTP/2的数据帧时只需要解析这些字节，就能准确的知道整个帧期望多少字节数来进行处理信息。我们先来了解一下帧中每个字段保存的信息：

名称 | 长度 | 描述
--- | --- | ---
Length | 3 字节 | 表示帧负载的长度，默认最大帧大小2^14
Type | 1 字节 | 当前帧的类型，下面会做介绍
Flags | 1 字节 | 具体帧的标识
R | 1 字节 | 保留位，不需要设置，否则可能带来严重后果
Stream Identifier | 31 位 | 每个流的唯一ID
Frame Payload | 不固定 | 真实帧的长度，真实长度在Length中设置

### HTTP/1.1、HTTP/2、HTTP/3 演变

> - 图解网络-小林coding.pdf

#### 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？

HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：
- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。
> 但是要等到第一个才能处理下一个请求

但 HTTP/1.1 还是有性能瓶颈：
- 请求 / 响应头部（Header）**未经压缩**就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；
- 发送冗长的⾸部。每次互相发送相同的⾸部造成的浪费较多；
- 服务器是**按请求的顺序响应的**，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；
- 没有**请求优先级**控制；
- 请求只能从客户端开始，服务器只能被动响应

#### 那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相⽐ HTTP/1.1 性能上的改进:

##### 1. 头部压缩

HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。

这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

##### 2. ⼆进制格式

HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输的效率。

##### 3. 数据流

HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

客户端还可以指定数据流的优先级。优先级⾼的请求，服务器就先响应该请求。

##### 4. 多路复⽤

HTTP/2 是**可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应**。

移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就**不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提⾼了连接的利⽤率**。

举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分

##### 5. 服务器推送

HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。

举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

#### HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化

HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以**⼀旦发⽣了丢包现象，就会触发 TCP 的᯿传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

- HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了

- HTTP/2 多个请求复⽤⼀个TCP连接，**⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求**。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！

UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部重传问题。

⼤家都知道 UDP 是不可靠传输的，但**基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输**。

- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。
- TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。
- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

所以， QUIC 是⼀个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复⽤的协议。

QUIC 是新协议，对于很多⽹络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以

HTTP/3 现在普及的进度⾮常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。
