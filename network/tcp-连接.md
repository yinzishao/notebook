# TCP连接的异常断开

> - [断开TCP连接](https://segmentfault.com/a/1190000017411330)

以上都是在理想的情况下发生的，理想状态下，一个`TCP`连接可以被长期保持。但是现实总是很骨感，在保持`TCP`连接的过程中很可能出现各种意外的情况，比如网络故障，客户端崩溃或者异常重启，在这种情况下，如果服务端没有及时清理这些连接，服务端将发生连接泄露，直至服务端资源耗尽拒绝提供服务（`connection refused exception`）。因此在实际应用中，服务器端需要采取相应的方法来探测`TCP`连接是否已经断连。探测的原理就是心跳机制，可以是应用层面的心跳，也可以是第三方的心跳，但是绝大部分类`Unix`系统均在`TCP`中提供了相应的心跳检测功能（虽然并不是`TCP`规范中的一部分）。

## 客户端程序崩溃或异常退出

当**客户端程序因未知原因崩溃或异常退出**后，**操作系统**会给服务端发送一条`RST`消息，阻塞模型下，服务端内核**无法主动通知应用层**出错，只有应用层主动调用`read()`或者`write()`这样的**`IO`系统调用**时，内核才会利用出错来通知应用层对端`RST`（`Linux`系统报`Connection reset by peer`）。**非阻塞**模型下，服务端`select`或者`epoll`会返回`sockfd`可读,**应用层对其进行读取时**，`read()`会报错`RST`。

哪些情况下，会**收到来自对端的`RST`消息**呢。

1.  `connect`一个不存在的端口，客户端会收到一条`RST`，报错`Connection refused`；
2.  程序崩溃或异常退出，会向对端发送。
3.  对端断电重启，`send`数据时会收到来自对端的`RST`。
4.  `close(sockfd)`时，直接丢弃接收缓冲区未读取的数据，并给对方发一个`RST`。这个是由`SO_LINGER`选项来控制的；

`TCP socket`在任何状态下，只要收到`RST`包，即可释放连接资源。

> 当**客户端程序因未知原因崩溃或异常退出**后(包括 `kill -9`、 `代码异常崩溃`)，**操作系统**会给服务端发送一条`RST`消息。。

## 客户端断电或网络异常

如果客户端断电或网络异常，并且**连接通道内没有任何数据交互**，服务端是感知不到客户端掉线的，此时**需要借助心跳机制**来感知这种状况，一般的做法是，服务端往对端发送一个心跳包并启动一个超时定时器，如果能正确收到对端的回应，说明在线，如果超时，可以进行一系列操作，比如重试、关闭连接等等。

## keep alive or heart beart


借鉴一下大神的[文章](https://www.cnblogs.com/youxin/p/4056041.html)

很多人都知道`TCP`并不会去主动检测连接的丢失，这意味着，如果双方不产生交互，那么如果网络断了或者有一方机器崩溃，另外一方将永远不知道连接已经不可用了。**检测连接是否丢失**的方法大致有两种：`keepalive`和`heart-beat`。

`Keepalive`是很多的TCP实现提供的一种机制，它允许连接在空闲的时候双方会发送一些特殊的数据段，并通过响应与否来判断连接是否还存活着（所谓`keep~~alive`）。我曾经写过[一篇关于keepalive的blog](https://blog.csdn.net/historyasamirror/article/details/5526486) ，但后来我也发现，**其实`keepalive`在实际的应用中并不常见**。为何如此？这得归结于`keepalive`设计的初衷。`Keepalive`适用于清除死亡时间比较长的连接。

比如这样的场景：一个用户创建`tcp`连接访问了一个`web`服务器，当用户完成他执行的操作后，很粗暴的直接拨了网线。这种情况下，这个`tcp`连接已经断开了，但是`web`服务器并不知道，**它会依然守护着这个连接**。如果`web server`设置了`keepalive`，那么它就能够在用户断开网线的大概几个小时以后，确认这个连接已经中断，然后丢弃此连接，回收资源。

采用`keepalive`，它会先要求此连接一定时间没有活动（一般是几个小时），然后发出数据段，经过多次尝试后（每次尝试之间也有时间间隔），如果仍没有响应，则判断连接中断。可想而知，**整个周期需要很长的时间**。

所以，如前面的场景那样，需要**一种方法能够清除和回收那些在系统不知情的情况下死去了很久的连接**，`keepalive`是非常好的选择。

但是，在大部分情况下，特别是分布式环境中，我们需要的是一个**能够快速或者实时监控连接状态的机制**，这里，`heart-beat`才是更加合适的方案。

`Heart-beat`（心跳），按我的理解，它的原理和`keepalive`非常类似，都是发送一个信号给对方，如果多次发送都没有响应的话，则判断连接中断。它们的不同点在于，`keepalive`是`tcp`实现中**内建**的机制，是在创建`tcp`连接时通过设置参数启动`keepalive`机制；而`heart-beat`则需要在`tcp`之上的**应用层实现**。一个简单的`heart-beat`实现一般测试连接是否中断采用的**时间间隔都比较短**，可以很快的决定连接是否中断。并且，由于是在应用层实现，因为**可以自行决定当判断连接中断后应该采取的行为**，而`keepalive`在判断连接失败后只会将连接丢弃。

关于`heart-beat`，一个非常有趣的问题是，应该在传输真正数据的连接中发送`心跳`信号，还是可以专门创建一个发送“心跳”信号的连接。比如说，`A`，`B`两台机器之间通过连接`m`来传输数据，现在为了能够检测`A`，`B`之间的连接状态，我们是应该在连接`m`中传输`心跳`信号，还是创建新的连接`n`来专门传输`心跳`呢？我个人认为两者皆可。如果担心的是端到端的连接状态，那么就直接在该条连接中实现`心跳`。但很多时候，关注的是网络状况和两台主机间的连接状态，这种情况下， 创建专门的`心跳`连接也未尝不可。

## Socket感知连接断开

### 正常情况

客户端正常关闭连接：

```
//发送FIN消息，说明客户端已经没有数据发送，服务端read时会返回-1或者null
socket.shutdownOutput();
//默认的SO_LINGER参数，客户端发送FIN消息，服务端read时会返回-1或者null
socket.close();
//设置了立即关闭，客户端发送RST消息，服务端`read`时会报`connection rest by peer`。
socket.close();
```

### 非正常情况

*   客户端程序崩溃或异常退出：服务端`read`时会报`connection rest by peer`。
*   断电重启：服务端发送心跳信息时，会收到客户端的`RST`消息，调用`read`时会报`connection rest by peer`。
*   断电或网络中断：服务端发送心跳信息后超时

## 例子

由于**服务端程序crash**了，此时在操作系统中的**套接字数据结构已经被释放**，因此在协议层收到数据包的时候无法找到对应的套接字进行处理，于是发送了一个RST报文。

> 这个是测试客户端一直发送数据的前提下，服务端crash掉，并接受到了客户端的请求，所以返回了RST报文。如果没有数据交互，是不是也是会发送FIN报文呢？

所以，从上面客户端的错误码和报文情况我们可以知道，在**kill进程时TCP协议是能够感知到的**，并且发送的FIN报文。

我们再进一步的思考一下，为什么kill进程会有FIN呢？这个与前面crash的差异在哪？其实kill进程是通过shell想内核发送了SIGKILL或者SIGTERM，内核接收到该信号之后会进行相应的扫尾工作，因此可以看到服务端发送了FIN报文。


## 总结

宕机、无数据交互： 如果客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。

崩溃、无数据交互: 所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃(包括 `kill -9`、 `代码异常崩溃`。)，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。

客户端主机宕机，又迅速重启、有数据交互： `send`数据时会收到来自对端的`RST`

有数据传输、客户端主机宕机，一直没有重启: 服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了。在 Linux 系统中，提供了一个叫 tcp_retries2 配置项，默认值是 15。这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。 不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核还会基于「最大超时时间」来判定。 每一轮的超时时间都是倍数增长的，比如第一次触发超时重传是在 2s 后，第二次则是在 4s 后，第三次则是 8s 后


## 参考链接
- [断开TCP连接](https://segmentfault.com/a/1190000017411330): 心跳
- [从TCP协议到TCP通信的各种异常现象和分析（下）](http://www.itworld123.com/2019/05/17/linux/network/2019-05-16-%E4%BB%8ETCP%E5%8D%8F%E8%AE%AE%E5%88%B0TCP%E9%80%9A%E4%BF%A1%E7%9A%84%E5%90%84%E7%A7%8D%E5%BC%82%E5%B8%B8%E7%8E%B0%E8%B1%A1%E5%92%8C%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8B%EF%BC%89/): 各个异常情况的具体测试
- [TCP 异常断开连接](https://mp.weixin.qq.com/s/XWyKGrkVE_OejOkn0sAEMg): 面试题


---
# TCP 最多有几个连接

> - [一台主机上只能保持最多 65535 个 TCP 连接吗？ - 张彦飞的回答 - 知乎](https://www.zhihu.com/question/361111920/answer/1828767342)

要想把这个问题搞清楚，关键的地方在于**要把TCP连接的两端里的客户端和服务端两个角色分开来讨论。** 因为它两对端口号的使用方式不一样，区分开了能讨论的更清晰。

先抛出结论，**无论是服务端还是客户端，单机支撑 100W 以上的连接都是没有问题的。**

我在 4GB 的机器上都测试过的。如果内存更大，能支持的连接数会更多。咱们先从理论讲起来。

## **一、TCP 并发理论基础**

### 1 服务器理论最大并发数

> TCP连接四元组是由源IP地址、源端口、目的IP地址和目的端口构成。

**当四元组中任意一个元素发生了改变，那么就代表的是一条完全不同的新连接**。

我们算下服务器上理论上能达成的最高并发数量。拿我们常用的 Nginx 举例，假设它的 IP 是 A，端口80。这样就只剩下源IP地址、源端口是可变的。

IP 地址是一个 32 位的整数，所以源 IP 最大有 2 的 32 次方这么多个。 端口是一个 16 位的整数，所以端口的数量就是 2 的 16 次方。

2 的 32 次方（ip数）× 2的 16 次方（port数）大约等于两百多万亿。

所以理论上，我们每个 server 可以接收的连接上限就是**两百多万亿**。（不过每条 TCP 连接**都会消耗服务器内存**，实践中绝不可能达到这个理论数字，稍后我们就能看到。）

### 2 客户端理论最大并发数

> 注意：这里的客户端是一个角色，并不具体指的是哪台机器。当你的 java/c/go 程序响应用户请求的时候，它是服务端。当它访问 redis/mysql 的时候，你这台机器就变成客户端角色了。这里假设我们一台机器只用来当客户端角色。

我们再算一下客户端的最大并发数的上限。

很多同学认为一台 Linux 客户端最多只能发起 64 k 条 TCP 连接。因为**TCP 协议规定的端口数量有 65535 个**，但是一般的系统里 1024 以下的端口都是保留的，所以没法用。可用的大约就是 64 k 个。

但实际上客户端可以发出的连接远远不止这个数。咱们看看以下两种情况

- **情况1：** 这个 64 k 的端口号实际上说的是一个 ip 下的可用端口号数量。而**一台 Linux 机器上是可以配置多个 IP 的**。假如配置了 20 个 IP，那这样一台客户端机就可以发起 120 万多个 TCP 连接了。

- **情况2：** 再退一步讲，假定一台 Linux 上确实只有一个 IP，那它就只能发起 64 k 条连接了吗？ 其实也不是的。

根据四元组的理论，只要服务器的 IP 或者端口不一样，即使客户端的 IP 和端口是一样的。这个四元组也是属于一条完全不同的新连接。

比如下面的两条连接里，虽然客户端的 IP 和端口完全一样，但由于服务器侧的端口不同，所以仍然是两条不同的连接。

*   连接1：客户端IP 10000 服务器IP 10000
*   连接2：客户端IP 10000 服务器IP 20000

所以一台客户端机器理论并发最大数是一个比服务器的两百万亿更大的一个天文数字（因为四元组里每一个元素都能变）。这里就不展开计算了，因为已经没有意义了。

### 3 Linux 最大文件描述符限制

linux 下一切皆文件，包括 socket。所以**每当进程打开一个 socket 时候，内核实际上都会创建包括 file 在内的几个内核对象**。该进程如果打开了两个 socket，那么它的内核对象结构如下图。

![](https://pic1.zhimg.com/50/v2-3072dc9abe9347a98bf947c9ed2feb8b_hd.jpg?source=1940ef5c)

进程打开文件时消耗内核对象，换一句直白的话就是**打开文件对象吃内存**。所以linux系统出于安全角度的考虑，在多个位置都限制了可打开的文件描述符的数量，包括系统级、进程级、用户进程级。

*   fs.file-max： 当前系统可打开的最大数量
*   fs.nr_open： 当前系统单个进程可打开的最大数量
*   nofile： 每个用户的进程可打开的最大数量

本文的实验要涉及对以上参数的修改。

### 4 TCP 连接的内存开销

介绍内存开销之前，需要先理解内核的内存使用方式。只有理解了这个，才能深刻理解 TCP 连接的内存开销。

Linux 内核和应用程序使用的是完全不同的两套机制。 Linux 给它的内核对象分配使用 SLAB 的方式。

一个 slab 一般由一个或者多个 Page 组成（每个 Page 一般为 4 KB）。在一个 slab 内只分配特定大小、甚至是特定的对象。这样当一个对象释放内存后，另一个同类对象可以直接使用这块内存。通过这种办法极大地降低了碎片发生的几率。

![](https://pic1.zhimg.com/50/v2-f38fa9e2ae302ccd7d7a832c86ec52b0_hd.jpg?source=1940ef5c)

Linux 提供了 slabtop 命令来按照占用内存从大往小进行排列，这对我们查看内核对象的内存开销非常方便。

在 Linux 3.10.0 版本中，创建一个socket 需要消耗 `densty、flip、sock_inode_cache、TCP` 四个内核对象。这些对象加起来总共需要消耗大约 3 KB 多一点的内存。

> 如果连接上有数据收发的话，还需要消耗发送、接收缓存区。这两个缓存区占用内存影响因素比较多，既受收发数据的大小，也受 tcp_rmem、tcp_wmem 等内核参数，还取决于服务器进程能否及时接收（及时接收的话缓存区就能回收）。总之影响因素比较多，不同业务之间实际情况差别太大，比较复杂。所以不在本文讨论范围之内。

## 二、百万连接达成实验

**1 调整客户端可用端口范围**

默认情况下，Linux 只开启了 3 万多个可用端口。但我们今天的实验里，客户端一个进程要达到 5 万的并发。所以，端口范围的内核参数需要修改。

```text
#vi /etc/sysctl.conf
net.ipv4.ip_local_port_range = 5000 65000

```

执行 sysctl -p 使之生效。

**2 调整客户端最大可打开文件数**

我们要测试百万并发，所以客户端的系统级参数 fs.file-max 需要加大到 100 万。另外 Linux 上还会存在一些其它的进程要使用文件，所以我们需要多打一些余量出来，直接设置到 110 万。

对于进程级参数 fs.nr_open 来说，因为我们开启 20 个进程来测，所以它设置到 60000 就够了。这些都在 /etc/sysctl.conf 中修改。

```text
#vi /etc/sysctl.conf
fs.file-max=1100000
fs.nr_open=60000
```

sysctl -p 使得设置生效。并使用 sysctl -a 查看是否真正 work。

```text
#sysctl -p
#sysctl -a
fs.file-max = 1100000
fs.nr_open = 60000
```

接着再加大用户进程的最大可打开文件数量限制（nofile）。这两个是用户进程级的，可以按不同的用户来区分配置。 这里为了简单，就直接配置成所有用户 \* 了。每个进程最大开到 5 万个文件数就够了。同样预留一点余地，所以设置成 55000。 这些是在 /etc/security/limits.conf 文件中修改。

> 注意 hard nofile 一定要比 fs.nr_open 要小，否则可能导致用户无法登陆。

```text
# vi /etc/security/limits.conf
*  soft  nofile  55000
*  hard  nofile  55000
```

配置完后，开个新控制台即可生效。 使用 ulimit 命令校验是否生效成功。

```text
#ulimit -n
55000
```

**3 服务器最大可打开文件句柄调整**

服务器系统级参数 fs.file-max 也直接设置成 110 万。 另外由于这个方案中服务器是用单进程来接收客户端所有的连接的，所以进程级参数 fs.nr_open， 也一起改成 110 万。

```text
#vi /etc/sysctl.conf
fs.file-max=1100000
fs.nr_open=1100000
```

sysctl -p 使得设置生效。并使用 sysctl -a 验证是否真正生效。

接着再加大用户进程的最大可打开文件数量限制（nofile），也需要设置到 100 万以上。

```text
# vi /etc/security/limits.conf
*  soft  nofile  1010000
*  hard  nofile  1010000
```

配置完后，开个新控制台即可生效。 使用 ulimit 命令校验是否成功生效。

**4 为客户端配置额外 20 个 IP**

假设可用的 ip 分别是 CIP1，CIP2，......，CIP20，你也知道你的子网掩码。

> 注意：这 20 个 ip 必须不能和局域网的其它机器冲突，否则会影响这些机器的正常网络包的收发。

在客户端机器上下载的源码目录 test02 中，找到你喜欢用的语言，进入到目录中找到 tool.sh。修改该 shell 文件，把 IPS 和 NETMASK 都改成你真正要用的。

为了确保局域网内没有这些 ip，最好先执行代码中提供的一个小工具来验证一下

```text
make ping
```

当所有的 ip 的 ping 结果均为 false 时，进行下一步真正配置 ip 并启动网卡。

```text
make ifup
```

使用 ifconfig 命令查看 ip 是否配置成功。

```text
#ifconfig
eth0
eth0:0
eth0:1
...
eth:19
```

## **总结**

上面实验只用了一种方法，还有另外一种方法，参见**[百看不如一练，动手测试单机百万连接的保姆级教程！](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/f_CMt2ni0vegB3-pf2BTTg)** 一文中的方案二。

总结下，一台主机上的 TCP 连接数并不会受端口号 65535 的限制，我们有很多的办法绕开。**最终限制最大 TCP 连接数的资源是机器上的内存**。

我们上述的实验**只涉及了连接本身的内存开销**，如果连接上有数据收发你们还需要消耗接收缓存区、发送缓存区内存开销。这个开销受实际收发速度、内核参数配置大小的影响，情况会比较复杂。


---
# 参考链接

- [网络](https://note.grianchan.com/%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C.html): 一些常见问题与总结
- [TCP、UDP、Socket、HTTP网络编程题](https://juejin.cn/post/6844904125692379143)
- [http 502 和 504 的区别](https://juejin.cn/post/6844903462048628749)
- [TCP协议面试灵魂10问](https://network.51cto.com/art/202007/620326.htm): 一些比较经典的问题提问和解答。
