###1、监控
mongodb可以通过profile来监控数据，进行优化。

查看当前是否开启profile功能用命令：```db.getProfilingLevel()```返回level等级，值为0|1|2，分别代表意思：0代表关闭，1代表记录慢命令，2代表全部。

开始profile功能为db.setProfilingLevel(level);

level为1的时候，慢命令默认值为**100ms**，更改为```db.setProfilingLevel(level,slowms)```如db.setProfilingLevel(1,50)这样就更改为50毫秒

通过```db.system.profile.find()``` 查看当前的监控日志。

通过执行```db.system.profile.find({millis:{$gt:500}})```能够返回查询时间在500毫秒以上的查询命令。

这里值的含义是
Value     | 含义
-------- | ---
ts | 命令执行时间
info | 命令的内容
query | 代表查询
order.order | 代表查询的库与集合
reslen | 返回的结果集大小，byte数
nscanned | 扫描记录数量
nquery | 后面是查询条件
nreturned | 返回记录数及用时
millis | 所花时间

如果发现时间比较长，那么就需要作优化。

- nscanned数很大，或者接近记录总数，那么可能没有用到索引查询。

- reslen很大，有可能返回没必要的字段。

- nreturned很大，那么有可能查询的时候没有加限制。

- mongo可以通过db.serverStatus()查看mongod的运行状态

###2、 数据库设计优化

1. 完全分离（范式化设计）
  ```
{
     "_id" : ObjectId("5124b5d86041c7dca81917"),
     "title" : "如何使用MongoDB", 
      "author" : [ 
               ObjectId("144b5d83041c7dca84416"),
              ObjectId("144b5d83041c7dca84418"),
              ObjectId("144b5d83041c7dca84420"),
     ]
 }
   ```
 
 在这种情况下查询性能显然是不理想的。但当某位作者的信息需要修改时，范式化的维护优势就凸显出来了，我们无需考虑此作者关联的图书，直接进行修改此作者的字段即可。
2. 完全内嵌（反范式化设计） 

	```
	{
	"_id" : ObjectId("5124b5d86041c7dca81917"),
	"title" : "如何使用MongoDB",
	"author" : [
	         {
	             　　　　 "name" : "丁磊"
	            　　　　  "age" : 40,
	              　　　　"nationality" : "china",
	         },
	         {
	            　　　　  "name" : "马云"
	           　　　　   "age" : 49,
	            　　　　  "nationality" : "china",
	         },
	         {
	            　　　　  "name" : "张召忠"
	           　　　　   "age" : 59,
	           　　　　   "nationality" : "china",
	         },
	]}
	```
	在查询的时候直接查询图书即可获得所对应作者的全部信息，但因一个作者可能有多本著作，当修改某位作者的信息时时，我们需要遍历所有图书以找到该作者，将其修改。
  
3. 部分内嵌（折中方案） 
	```
	{
	       "_id" : ObjectId("5124b5d86041c7dca81917"),
	       "title" : "如何使用MongoDB",
	       "author" : [ 
	               {
	                     　　　　"_id" : ObjectId("144b5d83041c7dca84416"),
	                   　　　　  "name" : "丁磊"
	                },
	                {
	                    　　　　 "_id" : ObjectId("144b5d83041c7dca84418"),
	                  　　　　   "name" : "马云"
	                },
	                {
	                    　　　　 "_id" : ObjectId("144b5d83041c7dca84420"),
	                   　　　　  "name" : "张召忠"
	                },
	      ]
	  }
	```
	这种方式是一种相对折中的方式，既保证了查询效率，也保证的更新效率。但这样的方式显然要比前两种较难以掌握，难点在于需要与实际业务进行结合来寻找合适的提取字段。

> 在上面三个示例中，第一个示例的更新效率是最高的，但查询效率是最低的，而第二个示例的查询效率最高，但更新效率最低。所以在实际的工作中我们需要根据自己实际的需要来设计表中的字段，以获得最高的效率。

###3、设计数据库

**1. 业务热点数据和索引的总量要能全部放入内存中**
即：Memory > Index + Hot Data。一旦数据频繁地Swap，必然会造成MongoDB集群性能的下降。当内存成为瓶颈时，我们可以通过Scale Up或者Scale Out的方式进行扩展。

**2. 我们知道MongoDB的数据库是按文件来存储的**
例如：db1下的所有collection都放在一组文件内db1.0,db1.1,db1.2,db1.3……db1.n。数据的回收也是以库为单位进行的，数据的删除将会造成数据的空洞或者碎片，碎片太多，会造成数据库空间占用较大，加载到内存时也会存在碎片的问题，内存使用率不高，会造成数据频繁地在内存和磁盘之间Swap，影响MongoDB集群性能。因此将频繁更新删除的表放在一个独立的数据库下，将会减少碎片，从而提高性能。

**3. 单库单表绝对不是最好的选择。**
原因有三：
- 表越多，映射文件越多，从MongoDB的内存管理方式来看，浪费越多；
- 同理，表越多，回写和读取的时候，无法合并IO资源，大量的随机IO对传统硬盘是致命的；
- 单表数据量大，索引占用高，更新和读取速度慢。

**4. Local库容量设置。**
我们知道Local库主要存放oplog，oplog用于数据的同步和复制，oplog同样要消耗内存的，因此选择一个合适的oplog值很重要，如果是高插入高更新，并带有延时从库的副本集需要一个较大的oplog值（比如50G）；如果没有延时从库，并且数据更新速度不频繁，则可以适当调小oplog值（比如5G）。总之，oplog值大小的设置取决于具体业务应用场景，一切脱离业务使用场景来设置oplog的值大小都是耍流氓。

###4、 压缩数据

MongoDB **集群大量删除数据**后会存在大量的空洞:

- 这些空洞一方面会造成MongoDB数据存储空间较大
- 另外一方面这些空洞数据也会随之加载到**内存**中，导致内存的有效利用率较低，在机器内存容量有限的前提下，会造成热点数据频繁的Swap，频繁Swap数据，最终使得MongoDB集群服务能力下降，无法提供较高的性能。


####方案一：
- 我们可以使用MongoDB提供的在线数据收缩的功能，通过Compact命令```db.yourCollection.runCommand(“compact”);```进行Collection级别的数据收缩，去除Collectoin所在文件碎片。此命令是以Online的方式提供收缩，收缩的同时会影响到线上的服务，其次从我们实际收缩的效果来看，数据空洞收缩的效果不够显著。因此我们在实际数据碎片收缩时没有采用这种方案，也不推荐大家使用这种空洞数据的收缩方案。既然这种数据方案不够好，我们可以采用Offline收缩的

####方案二：
- 此方案收缩的原理是：把已有的空洞数据，remove掉，重新生成一份无空洞数据。那么具体如何落地？先预热从库；把预热的从库提升为主库；把之前主库的数据全部删除；重新同步；同步完成后，预热此库；把此库提升为主库。
 >具体的操作步骤如下：检查服务器各节点是否正常运行 ```ps -ef |grep mongod```登入要处理的主节点 /mongodb/bin/mongo--port 88888；做降权处理```rs.stepDown()```，并通过命令 ```rs.status()```来查看是否降权；切换成功之后，停掉该节点；检查是否已经降权，可以通过web页面查看status，我们建议最好登录进去保证有数据进入，或者是mongostat 查看； kill 掉对应mongo的进程： kill 进程号；删除数据，进入对应的分片删除数据文件，比如：``` rm -fr /mongodb/shard11/*；```重新启动该节点，执行重启命令，比如：如:```/mongodb/bin/mongod --config /mongodb/shard11.conf；```通过日志查看进程；数据同步完成后，在修改后的主节点上执行命令 ```rs.stepDown() ```，做降权处理。通过这种Offline的收缩方式，我们可以做到收缩率是100%，数据完全无碎片。当然做离线的数据收缩会带来运维成本的增加，并且在Replic-Set集群只有2个副本的情况下，还会存在一段时间内的单点风险。通过Offline的数据收缩后，收缩前后效果非常明显
