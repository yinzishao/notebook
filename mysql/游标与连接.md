# Data Cursor
数据指针（Data Cursor）或称光标，是在数据库引擎 (Database Engine)中，让开发人员或数据库管理员可以遍历、浏览检索结果的数据列(称为数据查询结果集, Result set)，**是主要用于在结果集中移动到某一数据列(row)的控制结构**。光标可以被看作是指向一组列中，代表某一列的指针。光标一次只能引用一列，但可以根据需要移动到结果集的其他列。

## 原理
数据指针是在数据库产生结果集时，由数据库引擎所产生的一个指针，用来指示当前正在访问的结果集的位置，经由这个指针，可以得到结果集中的数据列，并且可以依照需求来移动，但由于指针会占用服务器的资源，并且在指针开启期间**会激活共享锁定**(Shared Lock)，在多人使用的系统中容易造成死锁的问题，因此当前大部分的应用程序都是使用**仅前移型指针** (Forward-Only Cursor)。

## 仅前移型指针
仅前移型指针 (Forward-Only Cursor) 是**一旦将指针往前移时，其走过的指针之前的结果集就会被舍弃**，因此应用程序不能再往后移动指针，但也因此让服务器只需要记住指针在结果集中当前的位置即可，这让它消耗的资源只有指针而已，是最省资源的一种指针，在实务中被广泛使用，像 ADO.NET 的 DataReader 就只限定只能使用 Forward-Only Cursor。

-[指针](https://zh.wikipedia.org/wiki/%E6%8C%87%E6%A8%99_(%E8%B3%87%E6%96%99%E5%BA%AB))


## SSCursor

pymysql.cursors.SSCursor

无缓冲游标，主要用于返回大量数据的查询，或者通过慢速网络连接到远程服务器。

这将获取所需的数据行，而不是将每一行数据复制到缓冲区中。这样做的好处是客户机使用更少的内存，在慢速网络上传输时或者如果结果集非常大，返回的行要快得多。

不过，这也有局限性。MySQL协议不支持返回总行数，所以知道有多少行的唯一方法对返回的每一行进行迭代。而且，目前它还不是可能向后滚动，因为只有当前行保存在内存中。


---

# cursor vs connection区别
根据底层实现，**可能会生成多个游标，共享到数据库的同一连接**。关闭游标将**释放与查询相关联的资源**，包括从未从数据库中提取（或提取但未使用）的任何结果，但**不会消除与数据库本身的连接**，这样您就可以在同一数据库上获取新的游标，而无需再次验证。

- [cursor vs connection](https://stackoverflow.com/a/53182224)

---

# peewee

Peewee使用线程本地存储跟踪连接状态，使Peewee数据库对象可以安全地与多个线程一起使用。**每个线程都有自己的连接，因此任何给定的线程在给定的时间只能打开一个连接**。

- [thread-safety](http://docs.peewee-orm.com/en/latest/peewee/database.html#thread-safety)

## 连接池：
在多线程应用程序中，最多将打开max_connections。每个线程（或者，如果使用gevent，则为greenlet）将具有其自己的连接。

默认情况下，应用程序需要做的就是确保连接完成后关闭，并将它们返回到池中。对于web应用程序，这通常意味着在请求开始时，您将打开一个连接，当您返回一个响应时，您将关闭该连接。
- [为什么需要主动close掉](https://www.cnblogs.com/xueweihan/p/6698456.html)

- [flask不断创建数据库连接例子](http://dev.huaweidns.com/archives/29/)
- [About connection pool](https://github.com/coleifer/peewee/issues/1143)

> flask是因为每个请求都是一个线程？(不太对吧，有空用django试试)然后线程回收之后，并没有执行close()，所以导致数据库连接没有释放？然后本地主线程测试的时候，都是复用同个线程的连接，而且主线程退出也能释放连接。

- [Do peewee models automatically close the connection?](https://stackoverflow.com/a/46681567)

> 注意文档的排版！注意问题的前后文。自己重新看都脑瓜子疼

---
# Django的连接池

- [connection](../web/django/连接池.md)

---
# Prepare Statement

- [MySQL又双叒崩了——记beego的stmt优化](https://mp.weixin.qq.com/s/jehtP2WniN8Zkn-tyJZ88g)

而 beego 内部的所有的SQL查询，基本上都是通过 Prepare Statement 来执行的，这主要是因为 Prepare Statement 可以性能和安全方面的优势：

- 性能优势： Prepare Statement 会被预编译，**执行计划也会被缓存**；
- 安全：因为 Prepare Statement 在执行的时候是绑定参数的，也就是它不会把参数视为指令的一部分。这可以**防范大多数的 SQL 注入攻击**。

beego 所有的 SQL 执行都是通过 Prepare Statement 来实现的。

但是问题来了，为什么会创建这么多的 Prepare Statement 呢？所以我们的分析比较可能的原因是：

- beego 内部每次查询都创建了 Prepare Statement ，没有复用，也没有关闭；
- 用户绕开了标准`orm`，使用了我们提供的执行原始 SQL 的功能；
- 用户部署了非常多的实例 beego 实例；

通过跟用户的交流，确定了用户的确使用到了我们执行原始 SQL 的功能。而且他们犯了一个很严重的错误：即直接拼接 SQL 参数，而不是通过绑定参数来执行。

```
//git hash:cc0eacbe023b95f74c240b35419c14722df45041
//orm/db_alias.go
type DB struct {
    *sync.RWMutex
    DB    *sql.DB
    //此处没有对 stmts 的 size进行限制
    stmts map[string]*sql.Stmt
}

func (d *DB) getStmt(query string) (*sql.Stmt, error) {
    d.RLock()
    if stmt, ok := d.stmts[query]; ok {
        d.RUnlock()
        return stmt, nil
    }

    stmt, err := d.Prepare(query)
    if err != nil {
        return nil, err
    }
    d.Lock()
    d.stmts[query] = stmt
    d.Unlock()
    return stmt, nil
}
```
乍一看，这代码看起来毫无破绽。但是实际上，它有两个问题：

1. stmts 变量是简单的 map 结构，并不存在数量限制；
2. 在 17-23 行之间有并发问题。

一般人可能会觉得，怎么会有并发问题呢？往 map 里面塞进去东西的确没有并发问题。问题出在 d.Prepare(query) 这一句。

当多个 goroutine 发现 stmts 里面并没有缓存当前 query 的时候，就会同时创建出来新的`stmt`，但是最终都会试图放进去 map 里面，**加锁只会让他们排好队一个个放，但是后面的会覆盖前面的**。而**被覆盖的，却没有被关闭掉**。

解决方案

从前面分析，我们实际上要解决两个问题：

1. 设置缓存的`Prepare Statement`的数量的上限；
2. 在缓存不命中的时候，有且只有一个 Prepare Statement 被创建出来；

## 设置上限

第一个问题，要解决很简单，比如说我们维护一个缓存上限的值，而后再往 map 里面塞值之前先判断一下有没有超出上限。

这种方案的缺点就是谁先被缓存了，就永远占了位置，后面的 SQL 将无法享受到缓存`Prepare Statement`的优势。

那么很显然，我们可以考虑是用 LRU 来解决上限的问题。很显然，根据程序运行的特征，LRU 缓存局部热点更加契合局部性原理。我们只需要在 LRU 淘汰一个 Prepare Statement 的时候，关闭它就可以。

但是难点在于，这个被淘汰的 Prepare Statement 可能还在被使用中。毕竟 golang 并没有类似于 Java 软引用之类的东西。

所以我们只能考虑说维持一个计数，如果有人使用，就 +1，使用完了就 -1。

当我们在 **LRU 淘汰的时候，利用 WaitGroup 的特性来等待所有的使用者释放 stmt**。

## double-check

之前提到的并发问题，其实根源在于没有正确使用 double-check 。当我们加了写锁以后，需要进一步判断，有没有因为并发，而其它的 goroutine 刚才先获得了写锁，创建出来了 Prepare Statement 。

> 注意的是？: `计数 + 1. 这一步必须在这个方法内完成。 否则可能在LRU淘汰之后，执行Close之前，用户误+1，而stmt又被随后Close了`。也就是外层调用执行方法exec的时候计数+1，而不是从getStmtDecorator进行计数导致的。如果是里面创建的话，因为是读锁，会读不到数据？读写锁的用法？

## 总结

经过我们前面的分析，可以看到，这个问题的根源在于我们设计这个`Prepare Statement`的时候，并没有做好兜底的准备，从而导致了用户 MySQL的崩溃。

另外一方面，我们也发现，在 golang 里面，类似于这种资源的关闭都不是很好处理，至少代码不会简洁。当某一个资源被暴露出去之后，在我们框架层面上要释放资源的时候，最重要的问题就是，这个东西到底还有没有人用。

所以我们只能依赖于通过使用一种计数的形式，来迫使使用者加减计数来暴露使用情况。它带来的问题就是，用户可能会遗忘，无论是遗忘增加计数，还是遗忘减少计数，最终都会出问题。这种用法体验并不太好，不知道有没有人有更好的方案。

## 参考链接
- [MySQL又双叒崩了——记beego的stmt优化](https://mp.weixin.qq.com/s/jehtP2WniN8Zkn-tyJZ88g)
- https://github.com/astaxie/beego/blob/develop/orm/db_alias.go
- https://github.com/astaxie/beego/commit/a5e8344a0a8518a1b7442d52d6f90e6b4d81dc6f#diff-983076a093073d7bbe379db891826ab5
- [去掉读锁的操作?](https://github.com/astaxie/beego/commit/c08b27111ca04110da9e92dd5541c25bf712cc47#diff-983076a093073d7bbe379db891826ab5R437)

---
# 参考链接

- [高性能数据库连接池的内幕](https://mp.weixin.qq.com/s?__biz=MzI3MzEzMDI1OQ==&mid=2651814835&idx=1&sn=cb775d3926ce39d12fa420a292c1f83d&scene=0#wechat_redirect): 全面介绍连接池原理，高性能的设计，优化实践，现有连接池的瓶颈及解决方案。同时也会介绍唯品会自研数据库连接池产品(代号：Caelus)。
    - 使用连接池面临的最大挑战： 连接池的性能。随着分库的增加，不管选用哪个连接池，线程的个数均会线性增长
    - TODO:

- [一文读懂连接池技术原理、设计与实现](https://juejin.cn/post/6844903513273663501): 分析三个典型的连接池的设计. 数据库连接池、RabbitMQ队列插入消息连接池、Thrift连接池
