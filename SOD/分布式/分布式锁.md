# 分布式锁用 Redis 还是 Zookeeper？

> - [分布式锁用 Redis 还是 Zookeeper？](https://juejin.im/post/6894853961761685517): 分析具体场景，两种解决办法的简单使用与对比。

## redis

- [分布式锁](../../redis/分布式锁.md)

## Zookeeper
Zookeeper是一种提供配置管理、分布式协同以及命名的中心化服务。

zk的模型是这样的：zk包含一系列的节点，叫做znode，就好像文件系统一样每个znode表示一个目录，然后znode有一些特性：

- 序节点：假如当前有一个父节点为/lock，我们可以在这个父节点下面创建子节点；

zookeeper提供了一个可选的有序特性，例如我们可以创建子节点“/lock/node-”并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号

- 也就是说，如果是第一个创建的子节点，那么生成的子节点为/lock/node-0000000000，下一个节点则为/lock/node-0000000001，依次类推。
- 临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。
- 事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：
    - 节点创建
    - 节点删除
    - 节点数据修改
    - 子节点变更

基于以上的一些zk的特性，我们很容易得出使用zk实现分布式锁的落地方案：
- 使用zk的临时节点和有序节点，每个线程获取锁就是在zk创建一个临时有序的节点，比如在/lock/目录下。
- 创建节点成功后，获取/lock目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点
- 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。
- 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。
- 比如当前线程获取到的节点序号为/lock/003,然后所有的节点列表为[/lock/001,/lock/002,/lock/003],则对/lock/002这个节点添加一个事件监听器。
- 如果锁释放了，会唤醒下一个序号的节点，然后重新执行第3步，判断是否自己的节点序号是最小。

比如/lock/001释放了，/lock/002监听到时间，此时节点集合为[/lock/002,/lock/003],则/lock/002为最小序号节点，获取到锁。

## 两种方案的优缺点比较
学完了两种分布式锁的实现方案之后，本节需要讨论的是redis和zk的实现方案中各自的优缺点。

对于redis的分布式锁而言，它有以下缺点：
- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。
- 另外来说的话，redis的设计定位决定了它的数据**并不是强一致性的**，在某些极端情况下，可能会出现问题。锁的模型不够健壮
- 即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题，关于redlock的讨论可以看How to do distributed locking
- redis分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。

但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且**大部分情况下**都不会遇到所谓的“极端复杂场景”

所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。

对于zk分布式锁而言:
- zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。
- 如果获取不到锁，只需要添加一个监听器就可以了，**不用一直轮询，性能消耗较小**。
- 但是zk也有其缺点：如果有较多的客户端**频繁的申请加锁、释放锁**，对于zk集群的压力会比较大。

### 小结
综上所述，redis和zookeeper都有其优缺点。我们在做技术选型的时候可以根据这些问题作为参考因素。

## 建议
通过前面的分析，实现分布式锁的两种常见方案：redis和zookeeper，他们各有千秋。应该如何选型呢？

就个人而言的话，我比较推崇zk实现的锁： 因为redis是有可能存在隐患的，可能会导致数据不对的情况。但是，怎么选用要看具体在公司的场景了。

如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。

那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis。


---
临时节点： zookeeper会自动长连接的，如果客户端中断了连接，不管是你主动还是被动，我都会在我的注册列表里卖弄，干掉你，并且解锁

---
# 幂等性

> - [幂等性浅谈](https://www.jianshu.com/p/475589f5cd7b): 简述幂等的常用三种思路。

## 幂等的常用思路

### 1. MVCC：
多版本并发控制，乐观锁的一种实现，在数据更新时需要去比较持有数据的版本号，版本号不一致的操作无法成功

### 2. 去重表

利用数据库表单的特性来实现幂等，常用的一个思路是在表上构建唯一性索引，保证某一类数据一旦执行完毕，后续同样的请求再也无法成功写入。

例子还是上述的博客点赞问题，要想防止一个人重复点赞，可以设计一张表，将博客id与用户id绑定建立唯一索引，每当用户点赞时就往表中写入一条数据，这样重复点赞的数据就无法写入。

### 3. TOKEN机制

这种机制就比较重要了，适用范围较广，有多种不同的实现方式。其核心思想是为每一次操作生成一个唯一性的凭证，也就是token。**一个token在操作的每一个阶段只有一次执行权，一旦执行成功则保存执行结果。对重复的请求，返回同一个结果**。

每一个环节执行时都先检测一下该订单id是否已经执行过这一步骤，对未执行的请求，执行操作并缓存结果，而对已经执行过的id，则直接返回之前的执行结果，不做任何操作。这样可以在最大程度上避免操作的重复执行问题，缓存起来的执行结果也能用于事务的控制等。


---
# 消息幂等性
> - [如何保障消息100%投递成功、消息幂等性？](https://mp.weixin.qq.com/s/I5GF-3UUbrVfgoIMJmLUbw): 从业务场景出发，从消息队列到幂等性的一些思考。

comfirm机制其实是一个异步监听的机制，是为了保证系统的高吞吐量，这样就导致了还是不能够100%保障消息不丢失，因为即使加上了confirm机制，消息在MQ内存中还没有刷盘到磁盘就宕机了，还是没法处理。

这样的机制其实就是一个补偿机制，我不管MQ有没有真正的接收到，只要我的Redis中的消息状态也是为【发送中】，就表示此消息没有正确成功投递。再启动定时任务去监控，发起补偿投递。

当然定时任务那边我们还可以加上一个补偿的次数，如果大于3次，还是没有收到ack消息，那就直接把消息的状态设置为【失败】，由人工去排查到底是为什么？

这样的话方案就比较完美了，保障了100%的消息不丢失（当然不包含磁盘也坏了，可以做主从方案）。

不过这样的方案，就会有可能发送多次相同的消息，很有可能MQ已经收到了消息，就是ack消息回调时出现网络故障，没有让生产者收到。
那就要要求消费者一定在消费的时候保障幂等性！

## 乐观锁方案
根据version版本，也就是在操作库存前先获取当前商品的version版本号，然后操作的时候带上此version号。我们梳理下，我们第一次操作库存时，得到version为1，调用库存服务version变成了2；但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传递的version还是1，再执行上面的sql语句时，就不会执行；因为version已经变为2了，where条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。

> 跟实例一样借用状态值作为版本号

## 唯一ID + 指纹码

原理就是利用数据库主键去重，业务完成后插入主键标识

唯一ID就是业务表的唯一的主键，如商品ID

指纹码就是为了区别每次正常操作的码，每次操作时生成指纹码；可以用时间戳+业务编号的方式。

上面的sql语句： `select count(1) from table where id = 唯一ID + 指纹码`

返回如果为0 表示没有操作过，那业务操作后就可以insert into t_check(唯一ID+指纹码)

返回如果大于0 表示操作过，就直接返回

- 好处：实现简单
- 坏处：高并发下数据库瓶颈
- 解决方案：根据ID进行分库分表进行算法路由

---
# ZAB
- [ZooKeeper 概念](https://zhuanlan.zhihu.com/p/44731983): 基本概念
- [面试官问：ZooKeeper是强一致的吗？怎么实现的？](https://juejin.cn/post/6919737776766189582)
- [Zookeeper集群两阶段提交原理](https://blog.csdn.net/huanglei_hacker/article/details/107582570)

## ZAB协议内容简介
ZAB协议包括两种基本的模式： 崩溃恢复 和 消息广播

### 消息广播
当集群中有**过半的**Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入 消息广播模式 。

当一台遵守ZAB协议的服务器启动后加入到集群中，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么加入的服务器会自觉的进入 数据恢复模式：找到Leader 所在的服务器，并与其进⾏数据同步，数据同步完成后参与到消息⼴播流程中。

ZAB协议的消息广播使用**原子广播协议**， 类似一个二阶段提交的过程 ，但又有所不同。

二阶段提交中，需要所有参与者反馈ACK后再发送Commit请求。要求所有参与者要么成功，要么失败。这样会产生严重的阻塞问题

ZAB协议中，Leader等待半数以上的Follower成功反馈ACK即可，不需要收到全部的Follower反馈ACK。

Zookeeper集群处理写请求时，主要分为以下几步：

- Leader节点，针对当前请求生成日志（Txn）
- Leader节点，持久化前请求生成日志（Txn），并向自己发送一个Ack
- Leader节点，把当前请求生成的日志（Txn）发送给其他所有的参与者节点（非Observer）
- Leader节点，阻塞等待Follower节点发送Ack过来（超过一半则解阻塞）
- Follower节点，接收到Leader节点发送过来的Txn
- Follower节点，持久化当前Txn，并向Leader节点发送一个Ack
- Leader节点，接收到了超过一半的Ack（加上自己发给自己的Ack），则解阻塞
- Leader节点，向Follower节点发送commit命令（异步发送的，不会阻塞Leader节点）
- Leader节点，执行Txn，更新内存（根据Txn更新DataBase）
- Follower节点，接收到Leader节点发送过来的commit命令
- Follower节点，执行Txn，更新内存（根据Txn更新DataBase）

> 向Follower节点发送commit命令（异步发送的），这一步挂了，有数据不一致问题？
