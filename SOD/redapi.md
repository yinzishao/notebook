
# 理念

redapi的好处：
- 方便测试
- 快速提供数据的能力
- 方便维护，所有查表都是在同一处地方，方便后续改策略、算法，服务升级和测试等场景能统一更改
- 对调用屏蔽了相关的底层数据库，数据相关遇到性能问题，能够在底层灵活调整相关存储策略。

后续：缓存策略的姿势、根据redash生成相关的文档、权限控制、更改后的自动化测试。

---
# 如何发布新的接口

- 更改redash的名称，引起调用的问题，调用用的是redash的标题

- 添加新的参数，兼容旧的情况。

- 返回列数更改。client返回的是tuple没有转为字段名返回。

- 同样的名称，更改了逻辑，如何发布。就应该是新的接口了。


我觉得应该是要新开接口，server不需要做默认参数的控制。新的client根据新的接口渲染好默认参数，并引去新的接口。旧的接口还保留着，等所有引用了client的项目更新到最新才可以去掉。client这个要处理好接口版本升级，名字要一致的问题。

---
# 问题
1. 如何完成redapi的版本控制，测试与ci/cd
2. 现在数据库查询的测试姿势问题，伪造整个数据链条，和伪造单个查询的mock数据
3. 所有查询都经过redapi，太多语句和sql比较细。语句复用？数据库中间件？还是得连数据库和自己查字段。其实问题就是灵活的查询要经过api吗？
4. 不是所有的话，业务控制的表和中台控制的表关联查询，会有in查询过多的case。
5. 数据库的克隆库的伪造成本，没有量化的指标
6. 权限控制问题，鉴权


-----
# query_conf.go

## QueryConfProvider接口

提供查询配置信息的QueryConfProvider接口

---
## MapQueryConfProvider

提供内存字典缓存的查询模板，当数据源存在的时候替换。

## DbQueryConfProvider类

属性: DSN、Query、ReloadInterval。

GetQueryConf方法：实现各种获取请求模板和数据源的类，

QueryConf类：数据库查询结果。查询语句、数据源等

通过定时器触发数据库查询进行更新。定时调用srv.loadQueries(ctx)方法，该方法通过查询数据库得到QueryConf类的结果。以进行各个数据源的数据库连接初始化，保存在srv.selectors属性里。并将各个查询实例成Query，放到srv.qs属性列表里。


# redapi.go

## Srv
Srv 提供接口给外部查询、

### handleQuery

查询逻辑入口

### loadQueries

初始化查询语句模板与数据源。在初始化服务的时候进行第一次装载，后面定时或者接口reload

### query2qs

loadQueries调用，将Query渲染成QuerySelector。

---
Query类：QueryConf、Srv、Selector、ps（用于拼SQL的参数）

## QuerySelector

属性： 查询语句类、外部服务、数据库源、缓存时间

### handleQuery

只有一个数据库查询方法


context使用？

好绕啊！类嵌套类的作为属性。


# 数据服务

> 有兴趣看看《大数据之路：阿里巴巴大数据实践》的数据服务章节是怎么吹牛逼的～

DWSOA 是数据服务的第一个阶段，也就是将业务方对数据的需求通过 SOA 服务的方式暴露出去。**由需求驱动，一个需求开发一个或者几个接口，编写接口文档，开放给业务方调用**。这种架构实现起来比较简单，但是其缺陷也是特别明显的。

- 一方面，接口粒度比较粗，灵活性不高，扩展性差，复用率低。随着业务方对数据服务的需求增加，接口的数量也会很快从一位数增加到两位数，从两位数增加到三位数，其维护成本可想而知。
- 另一方面 开发效率不高无法快速响应业务。一个接口从需求开发、测试到最终的上线，整个流程走完至少需要1天的时间，即使有时候仅仅是增加一、两个返回字段，也要走一整套流程，所以开发效率比较低，投入的人力成本较高。

DWSOA 阶段存在的明显问题，就是烟囱式开发，导致接口众多不好维护，因此需要想办法降低接口的数量。当时我们对这些需求做了调研分析，发现实现逻辑基本上就是从 DB 取数，然后封装结果暴露服务，并且很多接口其实是可以合并的。

OpenAPI 就是数据服务的第二个阶段。**具体的做法就是将数据按照其统计粒度进行聚合，同样维度的数据，形成一张逻辑表，采用同样的接口描述**。以会员维度为例 把所有以会员为中心的数据做成 张逻宽表，只要是查询会员粒度的数据，仅需要调用会员接口即可。通过段时间的实施，结果表明这种方式有效地收敛了接口数量。

然而，数据的维度并没有我们想象的那么可控，随着时间的推移，大家对数据的深度使用，分析数据的维度也越来越多，当时 OpenAPI生产已有近 100 个接口：同时也带来大量对象关系映射的维护工作量。于是，**在 OpenAPI 的基础上，再抽象一层，用 DSL (Domain SpecificLanguage ，领域专用语言）来描述取数需求**。新做一套 DSL 然有一定的学习成本 ，因此采用标准的 SQL 语法，在此基础上做了一些 限制和特殊增强 ，以降低学习成本。同时也封装了标准 DataSource ，可以使ORM (Object Relation Mapping ，对象关系映射）框架（目前比较主流的框架有 Hibernate MyBatis 等）来解决对象关系映射问题。

至此，所有的简单查询服务减少到只有一个接口 ，这大大降低了数据服务的维护成本。传统的方式查问题需要翻源码，确认逻辑：而 SmartDQ 只需要检查 SQL 的工作量，并且可以开放给业务方通过写 SQL 的方式对外提供服务 ，由服务提供者自己来维护 SQL ，也算是服务走向 DevOps个里程碑吧。

逻辑表虽然在 OpenAPI 阶段就已经存在，但是在SmartDQ 阶段讲更合适，因为 SmartDQ 把逻辑表的作用真正发挥出来了。 SQL 提供者只需关心逻辑表的结构，不需要关心底层由多少物理表组成，甚至不需要关心这些物理表是 HBase 还是 MySQL 的，是单表还是分库分表，**因为 SmartDQ 已经封装了跨异构数据源和分布式查询功能**。 此外，数据部门字段的变更相对比较频繁，这种底层变更对应用层来说应该算是最糟糕的变更之一了。 而逻辑表层的设计很好地规避了这个痛点，**只变更逻辑表中物理字段的映射关系**，并且即刻生效，对调用方来说完全无感知。

小结：接口易上难下，即使一个接口 也会绑定－批人（业务方、接口开发维护人员、调用方）。所以对外提供的数据服务接口 定要尽可能抽象，接口的数量要尽可能收敛，最后在保障服务质量的情况下，尽可能减少维护工作量。现在 SmartDQ 提供 300 多个 SQL 模板，每条 SQL承担多个接口 的需求，而我们只用一位同学来维护 SmartDQ

第四个阶段是统一的数据服务层（即 OneService ）。大家心里可能会有疑问： SQL 并不能解决复杂的业务逻辑啊。确实， SmartDQ只满足了简单的查询服务需求。我们遇到的场景还有这么几类：**个性化的垂直业务场景、实时数据推送服务、定时任务服务**。所以 OneService主要是提供多种服务类型来满足用户需求，分别是 OneService-SmartDQ、OneService-Lego 、OneService-iPush 、OneService-uTiming上面提到过， SmartDQ 不能满足个性化的取数业务场 ，可以使用Lego Lego 采用插件化方式开发服务，一类需求开发一个插件，目共生产5个插件。为了避免插件之间相互影响，我们将插件做成微服务，使用 Docker 做隔离。

> 第一个阶段： 根据需求驱动。 第二个阶段： 抽象到逻辑表层。 第三个阶段： SQL中间件。我们需要的是当前最合适的方案。
