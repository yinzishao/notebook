# seek

```
consumer.seek(TopicPartition(topic=kafka_topics, partition=0), 15500)
```
offset是可以指定的，但是如果查找的是不存在的。则按out of range 处理，可以选择**最新或者最开始**的。

seek_to_beginning： 从最开始处理

---
# 订阅
不管是init、assign、subscribe都是通过`self._subscription`处理的，subscribe可以添加listener进行回调


---
# Consumer

kafka.consumer.base.Consumer主要是做一些分区的初始化和元数据获取的工作、主动提交逻辑、获取信息的一些apis接口。

主动提交逻辑:
- 另起线程进行处理，通过时间触发器（ReentrantTimer）进行提交
- 每次获取消息通过_auto_commit方法的判断count_since_commit参数（消费条数）的容量进行判断。
不过好像`kafka/consumer/simple.py:295`会有重复计算的问题，不能单纯的消费条数？

kafka.consumer.simple.SimpleConsumer.get_messages
比较常见的获取逻辑：通过获取相应的条数的消息，控制是否等待获取到相应的条数和相应过期时间的逻辑。


---

新版的group的消费者，主要是通过_subscription、_coordinator、_client、_fetcher等进行操作

## 生成器

self._consumer_timeout： consumer_timeout_ms can be used to stop iteration early

next_v2 通过message_generator_v2获取数据，message_generator_v2里面通过poll获取数据，poll会返回空的数据{}，但是message_generator_v2里面的处理是一个for poll的数据，里面yield。当数据为空的时候就会导致next_v2里面的next得不到数据，但是捕获了StopIteration，在next_v2里面如果没设时间，则再次通过_message_generator_v2获取数据。所以next_v2会无限等待，不会把控制权交换出去。

### next_v2
kafka.consumer.group.KafkaConsumer.next_v2通过consumer_timeout_ms去判断是否拿数据，默认无限大。
然后通过_message_generator_v2()返回一个生成器，返回next(self._iterator)。
next_v2，里面会一直去获取，没有获取到也就不会返回数据，重新获取。


###　message_generator_v2
通过poll拉取数据，注释说道，生成器是有状态的，生成的情况可能会变得陈旧的，因为**可能在拿取数据的时候，通过更改offset**，例如seek、pause、lose assignment等。是指poll拿一批数据，就一定要消耗完？

通过poll获取数据，而且通过update_offsets=False，让poll不要更新offset，而是在一条一条更新offset。
通过iter(d.items(**kw))返回poll的得到的数据


### poll
timeout_ms: 如果缓冲区中没有可用的数据，则在轮询中等待的毫秒数。如果为0，则立即返回缓冲区中当前可用的所有记录，否则返回空值。不能是负数。默认值:0。也就是while True里面的逻辑，kafka/consumer/group.py:644。

返回是一个dict，topic和消息数组

### _poll_once
进行一轮轮询。除了检查新数据之外，它还**执行任何必要的心跳、自动提交和偏移更新**

在返回获取的记录之前，我们可以发送下一轮的获取，并避免在用户处理获取的记录时阻塞等待它们的响应来启用管道。

fetched_records： 可以获取上次已经获取到的数据，获取不到则通过send_fetches发送获取，获取得到也会再发一次，如上所说

> 重点还是在_XX类里面、future fetcher

？： self._fetcher.send_fetches()

# Fetcher

> 运用了很多collections.namedtuple，来进行一些抽象同用消息类。


---
注释：
```
        Returns: (records (dict), partial (bool))
            records: {TopicPartition: [messages]}
            partial: True if records returned did not fully drain any pending
                partition requests. This may be useful for choosing when to
                pipeline additional fetch requests.
```


---
# feature

feature 只是一个可以添加回调函数的对象。

in_flight_requests 由correlation_id作为key存储feature的队列，通过kafka.conn.BrokerConnection.recv获取到的返回结果，然后通过correlation_id获取得到response，然后返回给poll

---
# socket

- kafka.conn.BrokerConnection._send_bytes
- kafka.conn.BrokerConnection._recv

把feature扔进队列中，然后通过poll的时候发送，接收控制同步异步。
