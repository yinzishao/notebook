
# Linux性能优化：CPU篇

> - [Linux性能优化：CPU篇](https://zhuanlan.zhihu.com/p/180402964)

## 基本概念

- 系统平均负载：是处于**可运行或不可中断状态**的平均进程数。

- 可运行进程：使用 CPU 或等待使用 CPU 的进程

- 不可中断状态进程：正在等待某些 IO 访问，一般是和硬件交互，**不可被打断**（不可被打断的原因是为了保护系统数据一致，防止数据读取错误）

> 注意： 不可中断状态进程: 硬件的IO访问。负载高导致cpu使用率不一定高。

## 系统平均负载升高的原因

一般来说，系统平均负载升高意味着 CPU 使用率上升。但是他们**没有必然联系**，CPU 密集型计算任务较多一般系统平均负载会上升，但是**如果 IO 密集型任务较多也会导致系统平均负载升高但是此时的 CPU 使用率不一定高**，可能很低因为很多进程**都处于不可中断状态**，等待 CPU 调度也会升高系统平均负载。所以假如我们**系统平均负载很高，但是 CPU 使用率不是很高，则需要考虑是否系统遇到了 IO 瓶颈，应该优化 IO 读写速度**。所以系统是否遇到 CPU 瓶颈需要结合 CPU 使用率，系统瓶颈负载一起查看（当然还有其他指标需要对比查看，下面继续讲解）

> 不可中断状态导致CPU使用率低，而负载高。需要参考CPU使用率

## 命令

- top命令查看进程运行状态
- uptime查看系统瓶颈负载
- watch -d uptime: -d 参数表示高亮显示变化的区域
- lscpu查看 CPU 信息
- cat /proc/cpuinfo查看每个 CPU 核的信息
- mpstat：使用mpstat -P ALL 1则可以查看每一秒的 CPU 每一核变化信息，整体和top类似，好处是可以把每一秒（自定义）的数据输出方便观察数据的变化，最终输出平均数据
- pidstat：使用pidstat -u 1则是每隔 1 秒输出当前系统进程、CPU 数据：
- vmstat：工具可以查看系统的内存、CPU 上下文切换以及中断次数： vmstat 1(每隔1秒输出)


stress 命令使用
```
 // --cpu 8：8个进程不停的执行sqrt()计算操作
 // --io 4：4个进程不同的执行sync()io操作（刷盘）
 // --vm 2：2个进程不停的执行malloc()内存申请操作
 // --vm-bytes 128M：限制1个执行malloc的进程申请内存大小
 stress --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout 10s
```

主要验证 CPU、IO、进程数过多的问题

mpstat：查看此时 IO 消耗，但是实际上我们发现这里 CPU 基本都消耗在了 sys 即系统消耗上。

**iowait 无法升高的问题**，是因为案例中 stress 使用的是 sync()系统调用，它的作用是**刷新缓冲区内存到磁盘中**。对于新安装的虚拟机，**缓冲区可能比较小**，无法产生大的 IO 压力，这样**大部分就都是系统调用的消耗了**。所以，你会看到**只有系统 CPU 使用率升高**。解决方法是使用 stress 的下一代 stress-ng，它支持更丰富的选项，比如stress-ng -i 1 --hdd 1 --timeout 600（--hdd 表示读写临时文件）。

我们使用pidstat查找具体是哪个进程导致 IO 升高的。

top：这里使用 top 依旧是最方面的查看综合参数，可以得出stress是导致 IO 升高的元凶。

vmstat：工具可以查看系统的内存、CPU 上下文切换以及中断次数： vmstat 1(每隔1秒输出)

- **cs：则为每秒的上下文切换次数。**
- **in：则为每秒的中断次数。**
- r：就绪队列长度，正在运行或等待 CPU 的进程。
- b：不可中断睡眠状态的进程数，例如正在和硬件交互。

pidstat：使用pidstat -w选项查看具体进程的上下文切换次数： `pidstat -w -p 3217281 1`

其中cswch/s和nvcswch/s表示**自愿上下文切换和非自愿上下文切换**。

pidstat查看当前 CPU 信息和具体的进程上下文切换信息：
```bash
#-w表示查看进程切换信息，-u查看CPU信息，-t查看线程切换信息
pidstat -w -u -t 1
```

我们可以查看系统的`watch -d cat /proc/softirqs`以及`watch -d cat /proc/interrupts`来查看系统的**软中断和硬中断（内核中断）**。我们这里主要观察/proc/interrupts即可。


## 总结
**通过以上问题现象及解决思路可以总结出**：

- 平均负载高有可能是 CPU 密集型进程导致的
- 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了
- 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源

总结工具：mpstat、pidstat、top和uptime

## 上下文切换

一般每次**上下文切换都需要几十纳秒到数微秒的 CPU 时间**，如果切换较多还是很容易导致 CPU 时间的浪费在寄存器、内核栈以及虚拟内存等**资源的保存和恢复上**，这里同样会导致系统平均负载升高。

Linux 为每个 CPU 维护一个就绪队列，将 R 状态进程按照优先级和等待 CPU 时间排序，选择最需要的 CPU 进程执行。这里运行进程就涉及了**进程上下文切换的时机**：

- 进程时间片耗尽。
- 进程在系统资源不足（内存不足）。
- 进程主动sleep。
- 有优先级更高的进程执行。
- 硬中断发生。

## 线程和进程

- 当进程只有一个线程时，可以认为进程就等于线程。
- 当进程拥有多个线程时，这些**线程会共享相同的虚拟内存和全局变量等资源**。这些资源在上下文切换时是不需要修改的。
- 线程也有自己的私有数据，比如**栈和寄存器等**，这些在上下文切换时也是需要保存的。

## 中断上下文切换
中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以**中断上下文切换并不会与进程上下文切换同时发生**。由于中断会打断正常进程的调度和执行，所以**大部分中断处理程序都短小精悍，以便尽可能快的执行结束**。

自愿上下文切换：是指**进程无法获取所需资源，导致的上下文切换**。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。

非自愿上下文切换：则是**指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换**。比如说，**大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换**

### 模拟上下文切换
使用sysbench工具**模拟上下文切换**问题。

使用`sysbench --threads=64 --max-time=300 threads run`模拟 64 个线程执行任务

我们可以明显的观察到：

- 当前 cs、in 此时剧增。
- sy+us 的 CPU 占用超过 90%。
- r 就绪队列长度达到 16 个超过了 CPU 核心数 8 个。

pidstat查看当前 CPU 信息和具体的进程上下文切换信息`pidstat -w -u -t 1`： 我们可以看到大量的sysbench线程存在很多的上下文切换。

我们可以查看系统的`watch -d cat /proc/softirqs`以及`watch -d cat /proc/interrupts`来查看系统的软中断和硬中断（内核中断）。我们这里主要观察/proc/interrupts即可。

这里明显看出**重调度中断**（RES）增多，**这个中断表示唤醒空闲状态 CPU 来调度新任务执行**，


## **总结**
- 自愿上下文切换变多了，说明进程**都在等待资源**，有可能发生了 **I/O** 等其他问题。
- 非自愿上下文切换变多了，说明进程**都在被强制调度**，也就是都在争抢 CPU，说明 **CPU 的确成了瓶颈**。
- 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看/proc/interrupts文件**来分析具体的中断类型**

> TODO: 中断类型有什么？如何分析具体的中断类型的原因？

## CPU 使用率

除了系统负载、上下文切换信息，最直观的 CPU 问题指标就是 **CPU 使用率**信息。Linux 通过/proc虚拟文件系统向用户控件提供系统内部状态信息，其中/proc/stat则是 CPU 和任务信息统计。

我们可以使用top、ps、pidstat等工具方便的查询这些数据，可以很方便的看到 CPU 使用率很高的进程，这里我们可以通过这些工具初步定为，但是具体的问题原因还需要其他方法继续查找。

这里我们可以使用**perf top方便查看热点数据**，也可以使用perf record可以将当前数据保存起来方便后续使用perf report查看。

## **CPU 使用率问题排查**
这里总结一下 CPU 使用率问题及排查思路：

- 用户 CPU 和 Nice CPU 高，说明**用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题**。
- 系统 CPU 高，说明**内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题**。
- I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该**着重排查系统存储是不是出现了 I/O 问题**。
- 软中断和硬中断高，**说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序**。

## CPU 使用率
CPU 使用率主要包含以下几个方面：

- 用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。用户 CPU 使用率高，通常说明有**应用程序比较繁忙**。
- 系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明**内核比较繁忙**。
- 等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。iowait 高，通常说明**系统与硬件设备的 I/O 交互时间比较长**。
- 软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明**系统发生了大量的中断**。
- 除在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。

## 上下文切换
上下文切换主要关注 2 项指标：

- 无法获取资源而导致的自愿上下文切换。
- 被系统强制调度导致的非自愿上下文切换。

## **CPU 问题排查方向**
有了以上性能工具，在实际遇到问题时我们并不可能全部性能工具跑一遍，这样效率也太低了，所以这里可以先运行几个常用的工具 top、vmstat、pidstat 分析系统大概的运行情况然后在具体定位原因。

```markdown
top 系统CPU => vmstat 上下文切换次数 => pidstat 非自愿上下文切换次数 => 各类进程分析工具(perf strace ps execsnoop pstack)

top 用户CPU => pidstat 用户CPU => 一般是CPU计算型任务

top 僵尸进程 =>  各类进程分析工具(perf strace ps execsnoop pstack)

top 平均负载 => vmstat 运行状态进程数 =>  pidstat 用户CPU => 各类进程分析工具(perf strace ps execsnoop pstack)

top 等待IO CPU => vmstat 不可中断状态进程数  => **IO分析工具**(dstat、sar -d)

top 硬中断 => vmstat 中断次数 => 查看**具体中断类型**(/proc/interrupts)

top 软中断 => 查看具体中断类型(/proc/softirqs) => **网络分析工具**(sar -n、tcpdump) 或者 SCHED(pidstat 非自愿上下文切换)
```

> - 系统CPU： 排查上下文切换、中断。
> - 中断：着重排查内核中的中断服务程序、具体类型。非自愿上下文切换：抢占CPU。软中断、自愿上下文切换：网络IO。
> - 用户cpu： 程序问题。IO wait、不可中断状态进程数： IO（磁盘、网络）分析工具。

## **CPU 问题优化方向**
性能优化往往是多方面的，CPU、内存、网络等都是有关联的，这里暂且给出 CPU 优化的思路，以供参考。

### 程序优化
- 基本优化：**程序逻辑的优化**比如减少循环次数、减少内存分配，减少递归等等。
- 编译器优化：开启编译器优化选项例如gcc -O2对程序代码优化。
- 算法优化：降低**研发复杂度**，例如使用nlogn的排序算法，使用logn的查找算法等。
- 异步处理：例如把**轮询改为通知方式**
- 多线程代替多进程：某些场景**下多线程可以代替多进程**，因为上下文切换成本较低
- 缓存：包括**多级缓存**的使用（略）加快数据访问

### 系统优化
- CPU 绑定：**绑定到一个或多个 CPU 上**，可以提高 CPU 缓存命中率，**减少跨 CPU 调度带来的上下文切换问题**
- CPU 独占：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。
- 优先级调整：**使用 nice 调整进程的优先级，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理**。
- 为进程设置资源限制：**使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源**。
- NUMA 优化：支持 NUMA 的处理器会被划分为多个 Node，每个 Node 有本地的内存空间，**这样 CPU 可以直接访问本地空间内存**。
- 中断负载均衡：无论是软中断还是硬中断，**它们的中断处理程序都可能会耗费大量的 CPU**。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上。

> 缺乏实战生产环境的思考
