
Elasticsearch 的检索执行效率可以表示为：

**`O(num_of_files * logN)`**

其中 numoffiles 表示**索引文件段的个数**，**N 表示需要遍历的数据量**，从这里我们可以总结出提升查询性能可以考虑的两点：

- 减少遍历的索引**文件数量**
- 减少遍历的索引**文档总数**

从 Elasticsearch 自身来说，减少索引文件数量方面可以参考几点：

- **通过 optimize 接口强制合并段**
- 增大 index buffer/refresh_interval，**减少小段生成，控制相同数量的文档生成的新段个数**

不论是强制合并或者 index buffer/refresh_interval，都有其应用场景的限制，比如调整 index buffer / refresh_interval 会**相应的延长数据可见时间**；optimize 对**冷数据集比较适用**，如果数据在**不断变化过程**中，除了新段的生成，**老数据可能因为旧段过大而得不到物理删除**，反而造成较大的负担。

> 进行段合并过程中，因为涉及旧段过大导致的负担。而且使得许多缓存失效。

而减少文档总数方面，也可以做相应的优化：

- **减少文档更新**
- 指定 _routing 来**路由查询到指定的 shard**
- 通过 rollover 接口进行**冷热隔离**

> 通过读写一样的条件，进行指定分区的查询。类似partition hash by

这里尤其需要注意的是减少文档更新，由于 **LSM 追加写**的数据组织方式，更新数据其实是新增数据+标记老数据为删除状态的组合，真实参与计算的数据量是**有效数据和标记删除的数据量之和**，减少文档更新次数除了减少标记删除数据之外，还可以**降低段 merge 以及索引刷新的消耗**。

# 索引拆分

考虑到实际的业务场景，如果将海量数据存储于**单个索引，由于 shard 个数不可变**，一方面会使得索引分配大量的 shard，数据量持续增长会逐渐拖慢索引访问性能，另一方面想要通过扩展 shard 提高读写性能需要**重建海量数据，成本相当高昂**。
> 单索引大量的shard，如果需要扩展shard需要重建单索引的全量数据

为了增强索引的横向扩容能力，我们在**中间件层面进行了索引拆分**，参考实际的业务场景将大索引拆分为若干个小索引。 在索引拆分前，首先需要检查索引对应业务是否满足拆分的三个必要条件：

- 读写操作必定**会带入固定条件**
- 读写操作**维度唯一**
- 用户**不关心全局的搜索结果**

比较典型的比如店铺内商品搜索，不论买卖家都只关心**固定店铺内的商品检索结果，没有跨店铺检索需求**，后台店铺与商品也有固定的映射关系，这样就可以在中间件层面对读写请求进行解析，并路由到对应的子索引中，减少遍历的文档总量，可以在性能上获得明显的提升。

相对 Elasticsearch 自带的 _routing，这个方案具备更加灵活的控制粒度，比如可以配置白名单，将部分店铺数据路由到其他不同 SLA 级别的索引或集群，当然可以配合 _routing 以获得更好的表现。

**索引拆分首先会带来全局索引文件数据上升的问题**，不过因为没有全局搜索需求，所以不会带来实质的影响；其次比较需要注意的是**数据倾斜问题，在拆分前需要先通过离线计算模拟索引拆分效果，如果发现数据倾斜严重，就可以考虑将子索引数据进行重平衡**。

> 类似数据库的分区的方法，通过减少单个分区的文件数，索引文件需要遍历的文件数就更少了。比在总的索引文件，查找快的多。

> [数据倾斜的原因](/notebook/elasticsearch/优化数据倾斜.md#多索引): 索引的分片分配节点是互相没有关联的

---

# 冷热隔离
在查询维度不唯一的场景下，索引拆分就不适用了，为了解决此类场景下的性能问题，可以考虑对索引进行冷热隔离。 比如日志/订单类型的数据，具备比较明显的时间特征，大量的操作都集中在近期的一段时间内，这时就可以考虑依据时间字段对其拆分为冷热索引。

# 参考链接

- [有赞搜索系统的技术内幕](https://tech.youzan.com/search-tech-2/)
- [冷热隔离](优化冷热隔离.md)
