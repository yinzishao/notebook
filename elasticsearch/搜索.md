## 得分计算

布尔查询通过把所有符合 must 和 should 的子句得分加起来，然后除以 must 和 should 子句的总数为每个文档计算相关性得分。

must_not 子句并不影响得分；他们存在的意义是排除已经被包含的文档

像我们控制 match 查询的精度一样，我们也可以通过 minimum_should_match 参数**控制多少 should 子句需要被匹配**，这个参数可以是**正整数，也可以是百分比**。


---
## 分析控制

尽管我们说文档中每个字段的分析器是已经定好的。但是**字段可以有不同的分析器**，通过给那个字段配置一个指定的分析器或者直接使用类型，索引，或节点上的默认分析器。在索引的时候，一个字段的值会被配置的或者默认的分析器分析。

默认分词器是有一个规则，按顺序查找。


---
## 关联失效

为什么我们只用一个主分片来创建索引

然而，由于性能问题，Elasticsearch**不通过索引中所有的文档计算IDF**。每个分片会为**分片中**所有的文档计算一个本地的IDF取而代之。

事实证明，这并不是一个问题。你索引**越多的文档**，本地IDF和全局IDF的**区别就会越少**。在实际工作的数据量下，本地IDF立刻能够很好的工作。所以问题不是因为关联失效，而是**因为数据太少**。

或者通过dfs_query_then_fetch进行全局的IDF。

不要把 dfs_query_then_fetch 用于生产环境。它实在是没有必要。**只要有足够的数据就能够确保词频率很好的分布**。没有理由在每个你要执行的查询中添加额外的DFS步骤。

---
## TF-IDF

TF-IDF(term frequency–inverse document frequency)是一种用于**信息检索与数据挖掘的常用加权技术**，常用于挖掘文章中的关键词，而且算法简单高效，常被工业用于最开始的文本数据清洗。

词频（term frequency，tf）指的是**某一个给定的词语在该文件中出现的频率**。

逆向文件频率（inverse document frequency，idf）是**一个词语普遍重要性的度量**。某一特定词语的idf，可以由**总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到**。

> 文件数的度量

但是在本质上idf是一种**试图抑制噪声的加权**，并且单纯地认为**文本频率小的单词就越重要，文本频率大的单词就越无用**，显然这并不是完全正确的。idf的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以tf-idf法的精度并不是很高。

例子： 词频 (TF) 是一词语出现的次数除以该文件的总词语数。假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是3/100=0.03。一个计算文件频率 (IDF) 的方法是文件集里包含的文件总数除以测定有多少份文件出现过“母牛”一词。所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 lg(10,000,000 / 1,000)=4。最后的TF-IDF的分数为0.03 * 4=0.12。

- [相关度评分背后的理论](https://www.elastic.co/guide/cn/elasticsearch/guide/current/scoring-theory.html)


---
# 多字段查询的类型


### bool查询

bool 是如何计算评分的：

- 它会执行 should 语句中的两个查询。
- 加和两个查询的评分。
- 乘以匹配语句的总数。
- 除以所有语句总数（这里为：2）。

### dis_max查询

不使用 bool 查询，可以使用 dis_max 即分离 最大化查询（Disjunction Max Query） 。分离（Disjunction）的意思是 或（or） ，这与可以把结合（conjunction）理解成 与（and） 相对应。分离最大化查询（Disjunction Max Query）指的是： 将任何与任一查询匹配的文档作为结果返回，但只将最佳匹配的评分作为查询的评分结果返回

例子： 文档 1 的两个字段都包含 brown 这个词，所以两个 match 语句都能成功匹配并且有一个评分。文档 2 的 body 字段同时包含 brown 和 fox 这两个词，但 title 字段没有包含任何词。这样， body 查询结果中的高分，加上 title 查询中的 0 分，然后乘以二分之一，就得到比文档 1 更低的整体评分。

> title 和 body 字段是相互竞争的关系，所以就需要找到单个 最佳匹配 的字段。

dis_max 查询只会简单地使用 单个 最佳匹配语句的评分 _score 作为整体评分。

可以通过指定 tie_breaker 这个参数将其他匹配语句的评分也考虑其中： "tie_breaker": 0.3。
`最高得分 + (各个其余字段相加得分 * 0.3).`

## multi_match 查询
内部执行multi_match查询的方式取决于type参数，可以将其设置为：

### best_fields

查询的类型是 best_fields ，这表示它会为每个字段生成一个 match 查询，然后将它们组合到 dis_max 查询的内部

(默认) 查找与任何字段匹配的文档，使用最佳字段中的权重。 minimum_should_match 或 operator 这样的参数会被传递到生成的 match 查询中。

> type=best_fields时,slop无效,此时步长无限制

> operator=and 会使 minimum_should_match固定为100%

### most_fields

全文搜索被称作是 召回率（Recall） 与 精确率（Precision） 的战场： **召回率 ——返回所有的相关文档**； **精确率 ——不返回无关文档**。目的是在结果的第一页中为用户呈现最为相关的文档。

为了提高召回率的效果，我们**扩大搜索范围**——不仅返回与用户搜索词精确匹配的文档，还会返回我们认为与查询相关的所有文档。如果一个用户搜索 “quick brown box” ，一个包含词语 fast foxes 的文档被认为是非常合理的返回结果。

提高全文相关性精度的常用方式是为**同一文本建立多种方式的索引，每种方式都提供了一个不同的相关度信号 signal** 。主字段会**以尽可能多的形式的去匹配尽可能多的文档**：
- 词根形式
- 同义词
- 变音或者口音词

我们希望将所有匹配字段的评分合并起来，所以使用 most_fields 类型。这让 multi_match 查询用 bool 查询将两个字段语句包在里面，而不是使用 dis_max 查询。

用广度匹配字段 title 包括尽可能多的文档——以提升召回率——同时又使用字段 title.std 作为 信号 将相关度更高的文档置于结果顶部。

每个字段对于最终评分的贡献可以通过**自定义值 boost 来控制**。比如，使 title 字段更为重要，这样同时也降低了其他信号字段的作用:

```
            "type":        "most_fields",
            "fields":      [ "title^10", "title.std" ]
```

查找与任何字段匹配的文档，并组合每个字段的权重。**每个匹配子句的权重分加在一起，然后除以匹配子句的数量**。提高召回率。

主字段可以包含同义词，词干和没有变音符号的术语。 第二字段可以包含原始术语，并且第三字段可以包含带状疱疹。 通过组合所有三个字段的权重，我们可以将尽可能多的文档与主字段匹配，但使用第二和第三字段将最相似的结果推送到列表的顶部（多字段映射）

```
GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "quick brown fox",
      "type":       "most_fields",
      "fields":     [ "title", "title.original", "title.shingles" ]
    }
  }
}
```

用 most_fields 这种方式搜索也存在某些问题，这些问题并不会马上显现：
- 它被设计用来找到匹配任意单词的多数字段，而不是找到**跨越所有字段**的最匹配的单词。
- 它**不能使用operator或者minimum_should_match参数来减少低相关度结果带来的长尾效应**。(可以通过冗余跨字段copy_to解决)
- 词频对于每个字段是不一样的，而且它们之间的相互影响会导致不好的排序结果。

### cross_fields

使用相同的分析仪处理字段，就像它们是一个大字段。 在任何字段中查找每个字词。

为了让 cross_fields 查询以最优方式工作，**所有的字段都须使用相同的分析器**，具有相同分析器的字段会被分组在一起作为混合字段使用。

如果包括了不同分析链的字段，它们会以 best_fields 的相同方式被加入到查询结果中。

比较：most_fields对**每个字段**应用operator和minimum_should_match。不同字段的不同的术语频率可能会产生意外的结果


### phrase

对每个字段运行match_phrase查询，并合并每个字段的权重，详情参见：phrase and phrase_prefix.

### phrase_prefix

对每个字段运行match_phrase_prefix查询，并合并每个字段的权重，详情参见：phrase and phrase_prefix

- https://elasticsearch.apachecn.org/#/docs/243?id=%E5%A4%9A%E5%AD%97%E6%AE%B5%E6%9F%A5%E8%AF%A2%E7%9A%84%E7%B1%BB%E5%9E%8B

---
## tie_breaker

should 多个match分开时，是把得分相加,但如果是multi_match的best_fields时，得分计算跟tie_breaker相关。tie_breaker=1,相当于各个字段相加。tie_breaker=0.3,相当于最高得分 + (各个其余字段相加得分 * 0.3).


---
## match_phrase 短语匹配

类似 match 查询， match_phrase 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，但只保留那些包含 全部 搜索词项，且 位置 与搜索词项相同的文档。

鉴于一个短语查询仅仅排除了不包含确切查询短语的文档， 而 邻近查询 — 一个 slop 大于 0— 的短语查询将查询词条的**邻近度考虑到最终相关度** _score 中。 通过设置一个像 50 或者 100 这样的高 slop 值, **你能够排除单词距离太远的文档， 但是也给予了那些单词临近的的文档更高的分数。**

slop 参数告诉 match_phrase **查询词条相隔多远时仍然能将文档视为匹配** 。 相隔多远的意思是为了让查询和文档匹配你需要移动词条多少次。

> 注意 fox 和 quick 在这步中占据同样的位置。 因此将 fox quick 转换顺序成 quick fox 需要两步， 或者值为 2 的 slop 。

对多值字段（数组）使用短语匹配时会发生奇怪的事，在这样的情况下有一种叫做 position_increment_gap 的简单的解决方案， 它在字段映射中配置。**设定同个数组中不同元素的间隔**

```bash
PUT /my_index/_mapping/groups
{
    "properties": {
        "names": {
            "type":                "string",
            "position_increment_gap": 100
        }
    }
}
```

如果七个词条中有六个匹配， 那么这个文档对用户而言就已经足够相关了， 但是 **match_phrase 查询可能会将它排除在外**。相比将使用邻近匹配作为绝对要求， 我们可以将它作为 **信号** 使用， 作为许多潜在查询中的一个， 会对每个文档的最终分值做出**贡献**。

我们可以将一个简单的 match 查询作为一个 must 子句。 这个查询**将决定哪些文档需要被包含到结果集中**。 我们可以用 minimum_should_match 参数**去除长尾**。 然后我们可以**以 should 子句的形式添加更多特定查询**。 每一个匹配成功的都会**增加匹配文档的相关度**。

 ```bash
GET /my_index/my_type/_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "title": {
            "query":                "quick brown fox",
            "minimum_should_match": "30%"
          }
        }
      },
      "should": {
        "match_phrase": {
          "title": {
            "query": "quick brown fox",
            "slop":  50
          }
        }
      }
    }
  }
}
```

## 总结

实际生成环境中，也会用到类似主字段各种其他字段的这样方式（most_fields）来提升召回率。不过还是用best_fields查询，因为需要minimum_should_match参数来减少低相关度。

具体做法就是best_fields把相关的子字段（不同的分词器）加上，而且也会用上跨字段查询cross_fields来提高召回率, 通过步长进行邻近度的should查询，进行权重优化，提高准确性。
