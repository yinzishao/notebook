2.2 热点数据

热点数据的处理三步走，一是热点识别，二是热点隔离，三是热点优化。

2.2.1 热点识别

热点数据分为静态热点和动态热点，具体如下：

- 静态热点：能够提前预测的热点数据。大促前夕，可以根据大促的行业特点、活动商家等纬度信息分析出热点商品，或者通过卖家报名的方式提前筛选；另外，还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，即可视为热点商品
- 动态热点：无法提前预测的热点数据。冷热数据往往是随实际业务场景发生交替变化的，尤其是如今直播卖货模式的兴起——带货商临时做一个广告，就有可能导致一件商品在短时间内被大量购买。由于此类商品日常访问较少，即使在缓存系统中一段时间后也会被逐出或过期掉，甚至在db中也是冷数据。瞬时流量的涌入，往往导致缓存被击穿，请求直接到达DB，引发DB压力过大

因此秒杀系统需要实现热点数据的动态发现能力，一个常见的实现思路是：

- 异步采集交易链路各个环节的热点 Key 信息，如 Nginx采集访问URL或 Agent 采集**热点日志**（一些中间件本身已具备热点发现能力），提前识别潜在的热点数据
- 聚合分析热点数据，达到一定规则的热点数据，通过订阅分发推送到链路系统，各系统根据自身需求决定如何处理热点数据，或限流或缓存，从而实现热点保护

需要注意的是：

- 热点数据采集最好采用**异步方式**，一方面不会影响业务的核心交易链路，一方面可以保证采集方式的通用性
- 热点发现最好做到**秒级实时**，这样动态发现才有意义，实际上也是对核心节点的数据采集和分析能力提出了较高的要求


2.2.2 热点隔离

热点数据识别出来之后，第一原则就是将热点数据隔离出来，不要让 1% 影响到另外的 99%，可以基于以下几个层次实现热点隔离：

- 业务隔离。秒杀作为一种营销活动，卖家需要单独报名，从技术上来说，系统可以提前对已知热点做缓存预热
- 系统隔离。系统隔离是运行时隔离，通过分组部署和另外 99% 进行分离，另外秒杀也可以申请单独的域名，入口层就让请求落到不同的集群中
- 数据隔离。秒杀数据作为热点数据，可以启用单独的缓存集群或者DB服务组，从而更好的实现横向或纵向能力扩展

2.2.3 热点优化

热点数据隔离之后，也就方便对这 1% 的请求做针对性的优化，方式无外乎两种：

- 缓存：热点缓存是最为有效的办法。如果热点数据做了动静分离，那么可以长期缓存静态数据
- 限流：**流量限制**更多是一种保护机制。需要注意的是，各服务要时刻关注请求是否触发限流并及时进行review

2.2.4 小结

数据的热点优化与动静分离是不一样的，热点优化是基于二八原则对数据进行了纵向拆分，以便进行针对性地处理。热点识别和隔离不仅对“秒杀”这个场景有意义，对其他的高性能分布式系统也非常有参考价值。

----

4.1 高并发读

因此，在分层校验设定下，系统可以采用分布式缓存甚至LocalCache来抵抗高并发读。即允许读场景下一定的脏数据，这样只会导致少量原本无库存的下单请求被误认为是有库存的，等到真正写数据时再保证最终一致性，由此做到高可用和一致性之间的平衡。

实际上，分层校验的核心思想是：不同层次尽可能**过滤掉无效请求**，只在“漏斗” 最末端进行有效处理，从而缩短系统瓶颈的影响路径。

---

# 高可用

1 流量削峰

对于秒杀的目标场景，最终能够抢到商品的人数是固定的，无论 100 人和 10000 人参加结果都是一样的，即有效请求额度是有限的。并发度越高，无效请求也就越多。但秒杀作为一种商业营销手段，活动开始之前是希望有更多的人来刷页面，只是真正开始后，秒杀请求不是越多越好。因此系统可以设计一些规则，人为的延缓秒杀请求，甚至可以过滤掉一些无效请求。

1.1 答题

早期秒杀只是简单的点击秒杀按钮，后来才增加了答题。为什么要增加答题呢？主要是通过提升购买的复杂度，达到两个目的：

- 防止作弊。早期秒杀器比较猖獗，存在恶意买家或竞争对手使用秒杀器扫货的情况，商家没有达到营销的目的，所以增加答题来进行限制
- 延缓请求。零点流量的起效时间是毫秒级的，答题可以人为拉长峰值下单的时长，由之前的 <1s 延长到 <10s。这个时间对于服务端非常重要，会大大减轻高峰期并发压力；另外，由于请求具有先后顺序，答题后置的请求到来时可能已经没有库存了，因此根本无法下单，此阶段落到数据层真正的写也就非常有限了

需要注意的是，答题除了做正确性验证，还需要对提交时间做验证，比如<1s 人为操作的可能性就很小，可以进一步防止机器答题的情况。

答题目前已经使用的非常普遍了，本质是通过在入口层削减流量，从而让系统更好地支撑瞬时峰值。

1.2 排队

最为常见的削峰方案是使用消息队列，通过把**同步的直接调用转换成异步的间接推送**缓冲瞬时流量。除了消息队列，类似的排队方案还有很多，例如：

- 线程池加锁等待
- 本地内存蓄洪等待
- 本地文件序列化写，再顺序读

排队方式的弊端也是显而易见的，主要有两点：

- 请求积压。流量高峰如果长时间持续，达到了队列的水位上限，队列同样会被压垮，这样虽然保护了下游系统，但是和请求直接丢弃也没多大区别
- 用户体验。异步推送的实时性和有序性自然是比不上同步调用的，由此可能出现请求先发后至的情况，影响部分敏感用户的购物体验
- 排队本质是在业务层将一步操作转变成两步操作，从而起到缓冲的作用，但鉴于此种方式的弊端，最终还是要基于业务量级和秒杀场景做出妥协和平衡。

1.3 过滤

过滤的核心结构在于分层，通过在不同层次过滤掉无效请求，达到数据读写的精准触发。常见的过滤主要有以下几层：

1. 读限流：对读请求做限流保护，将超出系统承载能力的请求过滤掉
2. 读缓存：对读请求做数据缓存，将重复的请求过滤掉
3. 写限流：对写请求做限流保护，将超出系统承载能力的请求过滤掉
4. 写校验：对写请求做一致性校验，只保留最终的有效数据

过滤的核心目的是通过减少无效请求的数据IO保障有效请求的IO性能。

- [一个秒杀系统的设计思考](https://segmentfault.com/a/1190000020970562)

---
2.如何保证活动数据库和库存数据一致？

可以使用分布式事务或消息队列。

分布式事务：保证多个数据库的操作同时成功或者同时失败。对强一致性有要求的业务场景可以考虑使用分布式事务，比如银行转账

消息队列：基于生产者/消费者模型的组件，一般实现异步任务（非实时处理）时会引入消息队列。消息队列的好处是任务可以慢慢处理，不必同步处理等着响应结果。目前主流的消息队列有RocketMQ、Kafka等。使用场景除了异步任务之外，一般还用于失败的情况下重试处理，重复消费直到消费成功。

5.库存写回数据库的时机？

采用定时任务同步Redis的数据写回数据库。

> 如何保证redis的写操作后面的事务是正常运行的？第一种方法就是分布式事务，第二种办法就是redis保证持久化，写完redis后，定时任务同步redis的数据写回数据库，类似一种补偿的机制。
